<!DOCTYPE html><html lang="en"><head><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" as="style" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@200;300;400;500;600;700&amp;display=swap" data-optimized-fonts="true"/><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><meta property="og:title" content="Jina AI is a Neural Search Company"/><meta name="author" content="Jina AI"/><meta property="og:locale" content="en_US"/><meta property="og:site_name" content="Jina AI"/><meta property="og:image" content="https://jina.ai/assets/images/jina_banner_new.png"/><meta property="og:type" content="website"/><meta property="og:description" content="We provide business and developers an opensource neural search ecosystem for understanding unstructured data faster and easier."/><meta name="twitter:card" content="summary_large_image"/><meta property="twitter:image" content="https://jina.ai/assets/images/jina_banner_new.png"/><meta property="twitter:title" content="Jina AI is a Neural Search Company"/><meta property="twitter:description" content="We provide business and developers an opensource neural search ecosystem for understanding unstructured data faster and easier."/><meta name="twitter:site" content="@JinaAI_"/><meta name="twitter:creator" content="@JinaAI_"/><link rel="apple-touch-icon" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-96x96.png"/><link rel="icon" href="/favicon.ico"/><link rel="icon" type="image/png" sizes="192x192" href="/android-icon-192x192.png"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@200;300;400;500;600;700&amp;display=swap" data-optimized-fonts="true"/><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Open source neural search ecosystem for businesses and developers, allowing anyone to search any kind of data with high availability and scalability."/><meta property="og:url" content="https://jina.ai/"/><meta property="og:title" content="Jina AI | Jina AI is a Neural Search Company"/><meta property="og:description" content="Open source neural search ecosystem for businesses and developers, allowing anyone to search any kind of data with high availability and scalability."/><meta property="og:locale" content="en"/><meta property="og:site_name" content="Jina AI, Ltd"/><link rel="canonical" href="https://jina.ai/"/><title>Building Open Domain QA system with Jina | Jina AI</title><meta name="next-head-count" content="33"/><link rel="preload" href="/_next/static/css/e752e0fd702b7c34a608.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e752e0fd702b7c34a608.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script src="/_next/static/chunks/webpack-f47d69457824065d04c3.js" defer=""></script><script src="/_next/static/chunks/framework-2191d16384373197bc0a.js" defer=""></script><script src="/_next/static/chunks/main-18f21ab86863c15f7e5d.js" defer=""></script><script src="/_next/static/chunks/pages/_app-25c384a6dfe2e0ee232e.js" defer=""></script><script src="/_next/static/chunks/419-571d18b1d9b4fc2cda27.js" defer=""></script><script src="/_next/static/chunks/522-f41528aa8639e5478b36.js" defer=""></script><script src="/_next/static/chunks/100-7e862c46f33a42d3925c.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-b044910cba761441deff.js" defer=""></script><script src="/_next/static/TQ4qL1mPIDlUAIcAKpwVb/_buildManifest.js" defer=""></script><script src="/_next/static/TQ4qL1mPIDlUAIcAKpwVb/_ssgManifest.js" defer=""></script><style id="__jsx-3128403005">.dropdown.jsx-3128403005{--tw-bg-opacity:1;background-color:rgba(255,255,255,var(--tw-bg-opacity));--tw-text-opacity:1;color:rgba(74,85,104,var(--tw-text-opacity));top:5rem;width:100%;border-radius:0.75rem;}.dropdown.jsx-3128403005>.jsx-3128403005:not([hidden])~.jsx-3128403005:not([hidden]){--tw-divide-y-reverse:0;border-top-width:calc(1px * calc(1 - var(--tw-divide-y-reverse)));border-bottom-width:calc(1px * var(--tw-divide-y-reverse));border-style:solid;--tw-divide-opacity:1;border-color:rgba(235,235,235,var(--tw-divide-opacity));}</style><style id="__jsx-1573896879">.navbar.jsx-1573896879 a{display:inline-block;width:100%;}.navbar.jsx-1573896879 li:not(:first-child){margin-top:0.75rem;}.navbar.jsx-1573896879 a .btn{width:100%;}.navbar.jsx-1573896879 a:hover{--tw-text-opacity:1;color:rgba(0,129,129,var(--tw-text-opacity));}@media (min-width:640px){.navbar.jsx-1573896879 a,.navbar.jsx-1573896879 a .btn{width:auto;}.navbar.jsx-1573896879 li:not(:first-child){margin-top:0px;}.navbar.jsx-1573896879>li.jsx-1573896879:not(:last-child){margin-right:1.25rem;}}</style><style id="__jsx-649517993">.top-nav-bar.jsx-649517993{box-shadow:3px 6px 33px 0px #cdcdcd40;z-index:200;position:fixed;width:100vw;background:white;top:0;}</style><style id="__jsx-1324436386">.footer-links.jsx-1324436386 li{margin-top:0.25rem;}.footer-items-title.jsx-1324436386{font-size:1.375rem;line-height:1.5rem;-webkit-letter-spacing:0.22px;-moz-letter-spacing:0.22px;-ms-letter-spacing:0.22px;letter-spacing:0.22px;}</style><style id="__jsx-1956813867">.footer-left-margin.jsx-1956813867{width:20rem;height:inherit;background:no-repeat 40% 20%/30% url("/assets/images/planet-beige.svg");}.footer-right-margin.jsx-1956813867{width:16rem;height:inherit;background:no-repeat 10% 10%/50% url("/assets/images/planet-green.svg");}</style><style data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@200;300;400;500;600;700&display=swap">@font-face{font-family:'Poppins';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLFj_V1g.woff) format('woff')}@font-face{font-family:'Poppins';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDz8V1g.woff) format('woff')}@font-face{font-family:'Poppins';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrFJM.woff) format('woff')}@font-face{font-family:'Poppins';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLGT9V1g.woff) format('woff')}@font-face{font-family:'Poppins';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6V1g.woff) format('woff')}@font-face{font-family:'Poppins';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7V1g.woff) format('woff')}@font-face{font-family:'Poppins';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLFj_Z11lFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0900-097F,U+1CD0-1CF6,U+1CF8-1CF9,U+200C-200D,U+20A8,U+20B9,U+25CC,U+A830-A839,U+A8E0-A8FB}@font-face{font-family:'Poppins';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLFj_Z1JlFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Poppins';font-style:normal;font-weight:200;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLFj_Z1xlFd2JQEk.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Poppins';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDz8Z11lFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0900-097F,U+1CD0-1CF6,U+1CF8-1CF9,U+200C-200D,U+20A8,U+20B9,U+25CC,U+A830-A839,U+A8E0-A8FB}@font-face{font-family:'Poppins';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDz8Z1JlFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Poppins';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLDz8Z1xlFd2JQEk.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Poppins';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrJJbecnFHGPezSQ.woff2) format('woff2');unicode-range:U+0900-097F,U+1CD0-1CF6,U+1CF8-1CF9,U+200C-200D,U+20A8,U+20B9,U+25CC,U+A830-A839,U+A8E0-A8FB}@font-face{font-family:'Poppins';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrJJnecnFHGPezSQ.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Poppins';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiEyp8kv8JHgFVrJJfecnFHGPc.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Poppins';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLGT9Z11lFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0900-097F,U+1CD0-1CF6,U+1CF8-1CF9,U+200C-200D,U+20A8,U+20B9,U+25CC,U+A830-A839,U+A8E0-A8FB}@font-face{font-family:'Poppins';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLGT9Z1JlFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Poppins';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLGT9Z1xlFd2JQEk.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Poppins';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6Z11lFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0900-097F,U+1CD0-1CF6,U+1CF8-1CF9,U+200C-200D,U+20A8,U+20B9,U+25CC,U+A830-A839,U+A8E0-A8FB}@font-face{font-family:'Poppins';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6Z1JlFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Poppins';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLEj6Z1xlFd2JQEk.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Poppins';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7Z11lFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0900-097F,U+1CD0-1CF6,U+1CF8-1CF9,U+200C-200D,U+20A8,U+20B9,U+25CC,U+A830-A839,U+A8E0-A8FB}@font-face{font-family:'Poppins';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7Z1JlFd2JQEl8qw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Poppins';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/poppins/v15/pxiByp8kv8JHgFVrLCz7Z1xlFd2JQEk.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><script async="" src="https://www.googletagmanager.com/gtag/js?id=undefined"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'undefined', {
              page_path: window.location.pathname,
            });
          </script><body><div id="__next"><div class="jsx-649517993 top-nav-bar"><div class="md:max-w-screen-lg lg:max-w-screen-xl mx-auto px-8 py-6 undefined"><div class="jsx-1573896879 flex flex-wrap justify-between items-center"><div class="jsx-1573896879"><a class="jsx-1573896879" href="/"><div class="text-gray-900 flex items-center font-semibold text-3xl"><img src="/assets/images/logo.svg" alt="Jina.ai logo" class="w-24"/></div></a></div><div class="jsx-1573896879 md:hidden"><button type="button" aria-label="show menu" class="jsx-1573896879 p-3 text-gray-900 rounded-md hover:bg-white"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="1.5" fill="none" stroke-linecap="round" stroke-linejoin="round" class="jsx-1573896879 stroke-current h-6 w-6"><path d="M0 0h24v24H0z" stroke="none" class="jsx-1573896879"></path><path d="M4 6h16M4 12h16M4 18h16" class="jsx-1573896879"></path></svg></button></div><nav class="jsx-1573896879 w-full md:w-auto md:block mt-6 md:mt-0 hidden"><ul class="jsx-1573896879 navbar flex flex-col md:flex-row md:items-center font-medium text-xl text-gray-800 sm:p-0 bg-white sm:bg-transparent rounded"><a href="/careers" class="jsx-649517993"><span class="jsx-649517993 text-gray-700 text-lg mr-4 font-medium hidden md:inline-block">Careers</span></a><a href="/blog" class="jsx-649517993"><span class="jsx-649517993 text-gray-700 text-lg mr-4 font-medium hidden md:inline-block">Blog</span></a><a href="https://learn.jina.ai" class="jsx-649517993"><span class="jsx-649517993 text-gray-700 text-lg mr-4 font-medium hidden md:inline-block">Learn</span></a><div class="jsx-3128403005 md:hidden overflow-y-scroll"><ul class="jsx-3128403005 dropdown"><li class="jsx-3128403005 hover:bg-gray-200"><a href="/careers" rel="noopener noreferrer" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/careers-icon.svg" alt="careers icon" class="w-full h-full"/></div><a href="/careers" class="jsx-3128403005"><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Careers</span></a></div><span class="jsx-3128403005 text-xs text-gray-500">Interested in joining us? Find out what it&#x27;s like to work at Jina AI.</span></div></a></li><li class="jsx-3128403005 hover:bg-gray-200"><a href="/blog" rel="noopener noreferrer" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/news-icon.svg" alt="news icon" class="w-full h-full"/></div><a href="/blog" class="jsx-3128403005"><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Blog</span></a></div><span class="jsx-3128403005 text-xs text-gray-500">Check out the latest news about our company and products.</span></div></a></li><li class="jsx-3128403005 hover:bg-gray-200"><a href="https://learn.jina.ai" rel="noopener noreferrer" class="jsx-3128403005 py-2 px-4 block whitespace-no-wrap"><div class="jsx-3128403005 leading-4"><div class="jsx-3128403005 flex items-center"><div class=""><img src="/assets/images/icons/docs-icon.svg" alt="docs icon" class="w-full h-full"/></div><a href="https://learn.jina.ai" class="jsx-3128403005"><span class="jsx-3128403005 text-gray-800 font-semibold text-sm ml-2">Learn</span></a></div><span class="jsx-3128403005 text-xs text-gray-500">Jina Learning Bootcamp</span></div></a></li></ul></div></ul></nav></div></div></div><div style="margin-top:5.5rem"><div class="min-h-screen"><main><div class="container mx-auto px-5 flex flex-col items-center"><img src="/assets/images/blog/2021-11-29-odqa-part-1/banner.jpg" alt="Building Open Domain QA system with Jina-image" class="rounded-lg md:rounded-none shadow-md md:shadow-lg mb-4 mt-8 md:my-0 w-full xl:rounded-b-3xl"/><article class="mb-16 md:mb-32 pt-5 pb-10 md:py-20 md:max-w-6xl rounded-b-lg xl:rounded-3xl md:px-32 w-full xl:-mt-20 bg-white md:shadow-lg"><div class="mb-3"><div class="inline-block px-2 py-0 rounded text-primary-500 bg-primary-500 bg-opacity-20 mr-2 mb-2">odqa</div><div class="inline-block px-2 py-0 rounded text-primary-500 bg-primary-500 bg-opacity-20 mr-2 mb-2">qa chatbot</div></div><h1 class="text-xl md:text-4xl font-bold tracking-tighter leading-tight md:leading-none mb-6 md:text-left">Building Open Domain QA system with Jina</h1><div class="flex items-center justify-between text-gray-600 mb-12"><div class="flex items-center"><img src="/assets/images/team/avatar-default.svg" class="w-8 h-auto rounded-full border border-gray-500 mr-4" alt="Nan Wang"/><div class="text-gray-600">Nan Wang</div></div><time dateTime="2021-12-06">6 December, 2021</time></div><div class="mx-auto markdown"><p>Do you struggle to find the right answers to your question from dozens of documents? Do you want to find these answers by asking questions directly in natural languages? Do you get tired of figuring out the proper keywords for the search box? The solution to all of these problems is an intelligent <strong>Question Answering (QA)</strong> system. In this blog, we will discuss how to build the open domain QA system from scratch with Jina.</p>
<h2 id="open-domain-question-answering-odqa-in-2021">Open Domain Question Answering (ODQA) in 2021</h2>
<p>Searching for the right information is an integral part of our daily life.</p>
<p>When you are reading this post, you are likely wondering <em>“What is Jina?”</em>, <em>“How will it help me?"</em> or maybe <em>“What are the things to know before you start with  Jina?”</em>. The answers to these questions can be easily found in our <a href="https://docs.jina.ai/">documentation</a>. Given such factoid questions asked in natural languages, finding answers based on documents is formatted as <strong>Open Domain Question Answering (ODQA)</strong> in academics.</p>
<p>A standard ODQA pipeline is a two-stage system containing a <strong>retriever</strong> and <strong>reader</strong>. The retriever retrieves the candidate <strong>contexts</strong> via either the traditional or the neural retrieval methods. The reader extracts answers from the contexts.</p>
<p>This procedure is the same as how we answer the questions in an open-book examination. Suppose that we have little knowledge of the question but we are allowed to refer to the books during the exam. A common strategy is to firstly find the related chapters or passages and then read through the text to find the exact answer.</p>
<p class="image-only"><span class="image-wrapper"><img src="/assets/images/blog/2021-11-29-odqa-part-1/retriever-reader-pipeline.svg" alt=""></span></p>
<p>Let’s now look at different components of this open domain question answering pipeline and how they work in tandem to produce a smooth search interface capable of supporting natural language queries.</p>
<h2 id="retriever">Retriever</h2>
<p>Given a bunch of text documents, the retriever selects a few related passages as contexts based on the question. These contexts are later sent to the reader for extracting answers so the reader doesn’t have to read all the documents and search latency will be minimal. Let's look at two different retrieval methods and see how the execution differs for both of them.</p>
<h3 id="term-based-vs-dense-vector-retrieval">Term-based vs Dense-Vector retrieval</h3>
<p>Traditionally, the retriever is implemented using <strong>term-based methods</strong>, such as TF-IDF or BM25, which match keywords with an inverted index. This implementation is efficient but suffers from the issue of term mismatching. For example, when you want to know the core concepts in Jina and type <em>“What are the core concepts in Jina?”</em>, you will miss the most important document because the original text is written as <em>“... Document, Executor, and Flow are the three fundamental concepts”</em>. Because the search system does not know <em>“core concepts”</em> are semantically related to <em>“fundamental concepts”</em>.</p>
<p>Another issue with the term-base method is the expensive query. Questions such as  <em>“What is Jina?”</em> are usually considered expensive queries because such queries will return tons of unrelated results. This is rooted in the fact that the keyword-based search system does not understand the question and purely retrieves all the results containing the keyword <em>“Jina”</em>.</p>
<p>To address these issues, <strong>dense retrieval methods</strong> have been proposed to replace the term-based method and have been proven to outperform these traditional methods. Instead of building an inverted index and matching the exact keywords, the dense retrieval methods encode the questions and the passages into vectors in a high-dimensional space. The related passages are retrieved by comparing the vector of the question with the vectors of the passages.</p>
<p class="image-only"><span class="image-wrapper"><img src="/assets/images/blog/2021-11-29-odqa-part-1/retriever-comparason.svg" alt=""></span></p>
<h3 id="encoder">Encoder</h3>
<p>To encode the questions and the passages, one option is the widely-used pretrained language models. With Jina Hub, you can directly try out different encoders out-of-box.</p>
<p>Here we use the <code>TransfomerTorchEncoder</code> which wraps up the <a href="https://huggingface.co/transformers/main_classes/model.html">huggingface transformers library</a> and enables the user to use the pretrained models from huggingface transformers directly. Besides, some of the models from the huggingface model hub are supported as well. Here we use the model from <a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2">sentence-transformers/all-mpnet-base-v2</a>.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> jina <span class="hljs-keyword">import</span> Executor, Document, DocumentArray
encoder = Executor.from_hub(<span class="hljs-string">'jinahub://TransformerTorchEncoder'</span>)
da = DocumentArray([
    Document(text=<span class="hljs-string">'Jina is a neural search framework.'</span>),
    Document(text=<span class="hljs-string">'Jina relies heavily on multiprocessing.'</span>),
    Document(text=<span class="hljs-string">'Jina is backed by Jina AI.'</span>)])

encoder.encode(docs=da)
<span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> da:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'<span class="hljs-subst">{doc.embedding}</span>'</span>)
</code></pre>
<!-- <script src="https://gist.github.com/nan-wang/e4a872ec40803eabbbcc6618a4eccb1d.js"></script> -->
<blockquote>
<p><em><strong>Tips</strong>: If you want Jina to automatically install the extra dependencies, create a python virtual environment following the instructions at <a href="https://docs.python.org/3/library/venv.html">virtualenv</a> and change Line 2 to</em></p>
</blockquote>
<pre><code class="hljs language-diff"><span class="hljs-deletion">- encoder = Executor.from_hub('jinahub://TransformerTorchEncoder')</span>
<span class="hljs-addition">+ encoder = Executor.from_hub('jinahub://TransformerTorchEncoder', install_requirements=True)</span>
</code></pre>
<p>Notice that we encode the question and the context passages with the same encoder. This might not be ideal because they usually have very different semantic meanings. For example, <em>“What is Jina?”</em> has a very different meaning from <em>“Jina is a neural search framework”</em>.</p>
<p>A more reasonable approach would be to encode them differently. One of the SOTA models to achieve this is the encoder from <strong>Deep Passage Retrieval (DPR)</strong>, which has trained two BERT models jointly so that the question and the contexts are encoded differently but still into the same space. To choose whether the question or the context model, one can set the <code>encoder_type</code> argument. To try out DPR encoder, you just need to change the following line in the above code</p>
<pre><code class="hljs language-diff"><span class="hljs-deletion">- encoder = Executor.from_hub('jinahub://TransformerTorchEncoder')</span>
<span class="hljs-addition">+ encoder = Executor.from_hub('jinahub://DPRTextEncoder', uses_with={'encoder_type': 'context'})</span>
</code></pre>
<blockquote>
<p><em><strong>Tips</strong>: Find more information at Jina Hub about <a href="https://hub.jina.ai/executor/u9pqs8eb">TransformerTorchEncoder</a> and <a href="https://hub.jina.ai/executor/awl0jxog">DPRTextEncoder</a>.</em></p>
</blockquote>
<h3 id="vector-index">Vector Index</h3>
<p>For comparing the vectors and retrieving the <strong><em>top K</em></strong> nearest neighbors to the question vector, we can calculate the cosine similarities for each combination between the question and the passages. The complexity is <em><strong>O(n*log(n))</strong></em> due to the requirement of retrieving top K results.</p>
<p>Alternatively, we usually resort to the <strong>Approximate Nearest Neighbour (ANN)</strong> algorithms to get an approximated result. In Jina Hub, you can find both implementations easily</p>
<pre><code class="hljs language-python">indexer = Executor.from_hub(<span class="hljs-string">'jinahub://SimpleIndexer'</span>)
indexer.index(docs=da)

q_da = DocumentArray([Document(text=<span class="hljs-string">'What is Jina?'</span>)])

indexer.search(docs=q_da)
<span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> q_da[<span class="hljs-number">0</span>].matches:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'score: <span class="hljs-subst">{m.scores[<span class="hljs-string">"cosine"</span>].value:<span class="hljs-number">.4</span>f}</span>, text: <span class="hljs-subst">{m.text}</span>'</span>)
</code></pre>
<p>To try out the ANN indexer, you just need to change Line 1 as in the below code. Under the hood, we use an indexer based on <a href="https://github.com/nmslib/hnswlib">Hnswlib</a>, which is efficient and flexible in handling large amounts of vectors. The only bottleneck is memory usage because all the vectors are stored in memory in the format of float32.</p>
<pre><code class="hljs language-diff"><span class="hljs-deletion">- indexer = Executor.from_hub('jinahub://SimpleIndexer')</span>
<span class="hljs-addition">+ indexer = Executor.from_hub('jinahub://U1MIndexer')</span>
</code></pre>
<blockquote>
<p><em><strong>Tips</strong>: Find more information at Jina Hub about <a href="https://hub.jina.ai/executor/zb38xlt4">SimpleIndexer</a> and <a href="https://hub.jina.ai/executor/96v8ecrt">U1MIndexer</a>.</em></p>
</blockquote>
<h2 id="reader">Reader</h2>
<p>The reader extracts the exact answer from the context. Usually the contexts are long sentences containing multiple factoid and therefore we need the reader to extract the right answer based on the question. This is well studied as the machine reading comprehension problem. Given a question and the candidate contexts, the reader will return a score together with the most possible starting and ending position of the answers.</p>
<p class="image-only"><span class="image-wrapper"><img src="/assets/images/blog/2021-11-29-odqa-part-1/reader.svg" alt=""></span></p>
<p>For DPR we will use the pretrained reader model by Facebook Research for the ODQA problem. Under the hood it uses the BERT model to serve two purposes. Firstly, the representation of <code>[CLS]</code> token is used to calculate the relevant scores for each context to measure how relevant they are to the question. This part plays a role as a reranker with a cross-attention mechanism, which has more capacity than the dual encoder model. The downside is that this model is more expensive to compute and therefore it is only feasible to use on a small number of candidates.</p>
<p>The second usage of the BERT representation is to calculate the probabilities of being a START or END position. Two hidden layers are appended for calculating the probability of being a START or an END position. All the tokens share the same layer weights.</p>
<p class="image-only"><span class="image-wrapper"><img src="/assets/images/blog/2021-11-29-odqa-part-1/dpr_reader.svg" alt=""></span></p>
<p><code>DPRReaderRanker</code> is available directly at the <a href="https://hub.jina.ai/executor/gzhiwmgg">Jina Hub</a> as well.</p>
<pre><code class="hljs language-python">ranker = Executor.from_hub(<span class="hljs-string">'jinahub://DPRReaderRanker'</span>)
ranker.rank(docs=q_da)
<span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> q_da[<span class="hljs-number">0</span>].matches:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'score: <span class="hljs-subst">{m.scores[<span class="hljs-string">"relevance_score"</span>].value:<span class="hljs-number">.4</span>f}</span>, text: <span class="hljs-subst">{m.text}</span>'</span>)
</code></pre>
<h2 id="put-them-all-together-in-a-flow">Put them all together in a Flow</h2>
<p>Now we have gone through the components needed for building an ODQA system. The Jina Flow can help us line them together and serve as a service.</p>
<h3 id="index">Index</h3>
<p>We first create the Jina Flow and then index all the Documents so that the dense vector retriever can retrieve the context. The Documents are encoded by the <code>DPRTextEncoder</code> and stored by the <code>SimpleIndexer</code>.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> jina <span class="hljs-keyword">import</span> Document, DocumentArray, Flow

da = DocumentArray([
     Document(text=<span class="hljs-string">'Jina is a neural search framework that empowers anyone to build SOTA and scalable deep learning search applications in minutes.'</span>),
     Document(text=<span class="hljs-string">'Document, Executor, and Flow are the three fundamental concepts in Jina.'</span>),
     Document(text=<span class="hljs-string">'Jina is backed by Jina AI and licensed under Apache-2.0.'</span>)])

f = (Flow()
     .add(uses=<span class="hljs-string">'jinahub+docker://DPRTextEncoder'</span>, encoder_type=<span class="hljs-string">'context'</span>)
     .add(uses=<span class="hljs-string">'jinahub+docker://SimpleIndexer'</span>))

<span class="hljs-keyword">with</span> f:
     f.post(on=<span class="hljs-string">'/index'</span>, inputs=da, show_progress=<span class="hljs-literal">True</span>)
</code></pre>
<h3 id="query">Query</h3>
<p>After indexing the Documents, we build a query Flow following the retriever-reader structure.
We query with a question in natural languages and get back the answers with relevance scores.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> jina <span class="hljs-keyword">import</span> Flow, Document, DocumentArray

f = (Flow(expose_port=<span class="hljs-number">45678</span>)
     .add(uses=<span class="hljs-string">'jinahub+docker://DPRTextEncoder'</span>, encoder_type=<span class="hljs-string">'context'</span>)
     .add(uses=<span class="hljs-string">'jinahub+docker://SimpleIndexer'</span>)
     .add(uses=<span class="hljs-string">'jinahub+docker://DPRReaderRanker'</span>))

q_da = DocumentArray([Document(text=<span class="hljs-string">'What is Jina?'</span>)])

<span class="hljs-keyword">with</span> f:
    resp = f.post(on=<span class="hljs-string">'/search'</span>, inputs=q_da, return_results=<span class="hljs-literal">True</span>)

<span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> resp[<span class="hljs-number">0</span>].docs:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'question: <span class="hljs-subst">{doc.text}</span>'</span>)
    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> doc.matches:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f'score: <span class="hljs-subst">{m.scores[<span class="hljs-string">"relevance_score"</span>].value:<span class="hljs-number">.4</span>f}</span>, answer: <span class="hljs-subst">{m.text}</span>'</span>)
</code></pre>
<h3 id="host-a-restful-service">Host a RESTful service</h3>
<p>For hosting the service, we need to change the following line of codes,</p>
<pre><code class="hljs language-diff"><span class="hljs-deletion">- with f:</span>
<span class="hljs-deletion">-     f.post(on='/search', inputs=da, return_results=True)</span>
<span class="hljs-addition">+ with f:</span>
<span class="hljs-addition">+     f.cors = True</span>
<span class="hljs-addition">+     f.protocol = 'http'</span>
<span class="hljs-addition">+     f.block()</span>
</code></pre>
<p>Now you can query directly via RESTful API. The Swagger docs UI is available at <code>http://localhost:45678/docs</code></p>
<pre><code class="hljs language-sh">curl --request POST \
     -d <span class="hljs-string">'{"data": ["text": "What is Jina?"]}'</span> \
     -H <span class="hljs-string">'Content-Type: application/json'</span> 
     <span class="hljs-string">'http://localhost:45678/search'</span>
</code></pre>
<p>A more detailed documentation about the client-serving usage of Jina can be found at <a href="https://docs.jina.ai/fundamentals/flow/flow-as-a-service/#flow-as-a-service">Jina Docs</a></p>
<h2 id="summary">Summary</h2>
<p>In this post, we have a gentle walkthrough for building a two-stage ODQA system with Jina. Besides the retriever-reader pipeline, another choice is to replace the reader with a generator for generating answers based on the context.
Furthermore, with a large language model such as <code>GPT-3</code>, it is also possible to generate answers directly from the question without retrieving any context. However, efficiency and precision are potential issues in practice.</p>
<p>In the future posts, we will cover more about building ODQA systems with SOTA models in Jina.
Stay tuned and happy Searching!</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://arxiv.org/abs/2004.04906">Dense Passage Retrieval for Open-Domain Question Answering</a></li>
<li><a href="https://lilianweng.github.io/lil-log/2020/10/29/open-domain-question-answering.html">Lil'Log</a></li>
</ul></div></article></div></main></div></div><div class="jsx-1956813867"><div class="bg-primary-500 text-white"><div class="jsx-1956813867 flex flex-row justify-center md:justify-between px-6 md:px-0"><div class="jsx-1956813867 footer-left-margin hidden md:block"></div><div class="jsx-1956813867 flex justify-center flex-col md:flex-row"><div class="jsx-1956813867 pr-4 md:ml-0 md:py-16 md:mr-2 lg:mr-16 mt-16 md:mt-0"><div class="text-center md:text-left"><div class="flex md:justify-start"><div class="text-gray-900 flex items-center font-semibold text-3xl"><img src="/assets/images/logo-white.svg" alt="Jina.ai logo" class="w-24"/></div></div></div></div><div class="jsx-1956813867 grid grid-cols-2 sm:grid-cols-2 md:grid-cols-4 gap-16 py-16"><div class="jsx-1324436386 footer-links sm:text-left"><div class="jsx-1324436386 font-semibold text-white footer-items-title">Company</div><nav class="jsx-1324436386 mt-3"><ul class="jsx-1324436386"><li class="jsx-1956813867"><a class="jsx-1956813867" href="/careers/">Join us</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="/blog/">Blog</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://learn.jina.ai">Learn</a></li></ul></nav></div><div class="jsx-1324436386 footer-links sm:text-left"><div class="jsx-1324436386 font-semibold text-white footer-items-title">Products</div><nav class="jsx-1324436386 mt-3"><ul class="jsx-1324436386"><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://github.com/jina-ai/jina">Jina</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://hub.jina.ai">Hub</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://github.com/jina-ai/finetuner">Finetuner</a></li></ul></nav></div><div class="jsx-1324436386 footer-links sm:text-left"><div class="jsx-1324436386 font-semibold text-white footer-items-title">Legal</div><nav class="jsx-1324436386 mt-3"><ul class="jsx-1324436386"><li class="jsx-1956813867"><a class="jsx-1956813867" href="/legal/#terms-of-service">Terms of Service</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="/legal/#privacy-policy">Privacy Policy</a></li></ul></nav></div><div class="jsx-1324436386 footer-links sm:text-left"><div class="jsx-1324436386 font-semibold text-white footer-items-title">Social</div><nav class="jsx-1324436386 mt-3"><ul class="jsx-1324436386"><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://github.com/jina-ai/">GitHub</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://www.linkedin.com/company/jinaai/">LinkedIn</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://twitter.com/jinaAI_/">Twitter</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://www.youtube.com/c/JinaAI/">YouTube</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://slack.jina.ai/">Slack</a></li><li class="jsx-1956813867"><a class="jsx-1956813867" href="https://meetup.com/jina-community-meetup/">Meetup</a></li></ul></nav></div></div></div><div class="jsx-1956813867 footer-right-margin hidden md:block"></div></div><div class="text-center text-gray-100 text-sm py-2"><span class="block md:inline-block">© Jina AI 2020-2021. All rights reserved.</span></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Building Open Domain QA system with Jina","date":"2021-12-06","slug":"2021-11-29-odqa-part-1","author":"Nan Wang","content":"\u003cp\u003eDo you struggle to find the right answers to your question from dozens of documents? Do you want to find these answers by asking questions directly in natural languages? Do you get tired of figuring out the proper keywords for the search box? The solution to all of these problems is an intelligent \u003cstrong\u003eQuestion Answering (QA)\u003c/strong\u003e system. In this blog, we will discuss how to build the open domain QA system from scratch with Jina.\u003c/p\u003e\n\u003ch2 id=\"open-domain-question-answering-odqa-in-2021\"\u003eOpen Domain Question Answering (ODQA) in 2021\u003c/h2\u003e\n\u003cp\u003eSearching for the right information is an integral part of our daily life.\u003c/p\u003e\n\u003cp\u003eWhen you are reading this post, you are likely wondering \u003cem\u003e“What is Jina?”\u003c/em\u003e, \u003cem\u003e“How will it help me?\"\u003c/em\u003e or maybe \u003cem\u003e“What are the things to know before you start with  Jina?”\u003c/em\u003e. The answers to these questions can be easily found in our \u003ca href=\"https://docs.jina.ai/\"\u003edocumentation\u003c/a\u003e. Given such factoid questions asked in natural languages, finding answers based on documents is formatted as \u003cstrong\u003eOpen Domain Question Answering (ODQA)\u003c/strong\u003e in academics.\u003c/p\u003e\n\u003cp\u003eA standard ODQA pipeline is a two-stage system containing a \u003cstrong\u003eretriever\u003c/strong\u003e and \u003cstrong\u003ereader\u003c/strong\u003e. The retriever retrieves the candidate \u003cstrong\u003econtexts\u003c/strong\u003e via either the traditional or the neural retrieval methods. The reader extracts answers from the contexts.\u003c/p\u003e\n\u003cp\u003eThis procedure is the same as how we answer the questions in an open-book examination. Suppose that we have little knowledge of the question but we are allowed to refer to the books during the exam. A common strategy is to firstly find the related chapters or passages and then read through the text to find the exact answer.\u003c/p\u003e\n\u003cp class=\"image-only\"\u003e\u003cspan class=\"image-wrapper\"\u003e\u003cimg src=\"/assets/images/blog/2021-11-29-odqa-part-1/retriever-reader-pipeline.svg\" alt=\"\"\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eLet’s now look at different components of this open domain question answering pipeline and how they work in tandem to produce a smooth search interface capable of supporting natural language queries.\u003c/p\u003e\n\u003ch2 id=\"retriever\"\u003eRetriever\u003c/h2\u003e\n\u003cp\u003eGiven a bunch of text documents, the retriever selects a few related passages as contexts based on the question. These contexts are later sent to the reader for extracting answers so the reader doesn’t have to read all the documents and search latency will be minimal. Let's look at two different retrieval methods and see how the execution differs for both of them.\u003c/p\u003e\n\u003ch3 id=\"term-based-vs-dense-vector-retrieval\"\u003eTerm-based vs Dense-Vector retrieval\u003c/h3\u003e\n\u003cp\u003eTraditionally, the retriever is implemented using \u003cstrong\u003eterm-based methods\u003c/strong\u003e, such as TF-IDF or BM25, which match keywords with an inverted index. This implementation is efficient but suffers from the issue of term mismatching. For example, when you want to know the core concepts in Jina and type \u003cem\u003e“What are the core concepts in Jina?”\u003c/em\u003e, you will miss the most important document because the original text is written as \u003cem\u003e“... Document, Executor, and Flow are the three fundamental concepts”\u003c/em\u003e. Because the search system does not know \u003cem\u003e“core concepts”\u003c/em\u003e are semantically related to \u003cem\u003e“fundamental concepts”\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eAnother issue with the term-base method is the expensive query. Questions such as  \u003cem\u003e“What is Jina?”\u003c/em\u003e are usually considered expensive queries because such queries will return tons of unrelated results. This is rooted in the fact that the keyword-based search system does not understand the question and purely retrieves all the results containing the keyword \u003cem\u003e“Jina”\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eTo address these issues, \u003cstrong\u003edense retrieval methods\u003c/strong\u003e have been proposed to replace the term-based method and have been proven to outperform these traditional methods. Instead of building an inverted index and matching the exact keywords, the dense retrieval methods encode the questions and the passages into vectors in a high-dimensional space. The related passages are retrieved by comparing the vector of the question with the vectors of the passages.\u003c/p\u003e\n\u003cp class=\"image-only\"\u003e\u003cspan class=\"image-wrapper\"\u003e\u003cimg src=\"/assets/images/blog/2021-11-29-odqa-part-1/retriever-comparason.svg\" alt=\"\"\u003e\u003c/span\u003e\u003c/p\u003e\n\u003ch3 id=\"encoder\"\u003eEncoder\u003c/h3\u003e\n\u003cp\u003eTo encode the questions and the passages, one option is the widely-used pretrained language models. With Jina Hub, you can directly try out different encoders out-of-box.\u003c/p\u003e\n\u003cp\u003eHere we use the \u003ccode\u003eTransfomerTorchEncoder\u003c/code\u003e which wraps up the \u003ca href=\"https://huggingface.co/transformers/main_classes/model.html\"\u003ehuggingface transformers library\u003c/a\u003e and enables the user to use the pretrained models from huggingface transformers directly. Besides, some of the models from the huggingface model hub are supported as well. Here we use the model from \u003ca href=\"https://huggingface.co/sentence-transformers/all-mpnet-base-v2\"\u003esentence-transformers/all-mpnet-base-v2\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e jina \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Executor, Document, DocumentArray\nencoder = Executor.from_hub(\u003cspan class=\"hljs-string\"\u003e'jinahub://TransformerTorchEncoder'\u003c/span\u003e)\nda = DocumentArray([\n    Document(text=\u003cspan class=\"hljs-string\"\u003e'Jina is a neural search framework.'\u003c/span\u003e),\n    Document(text=\u003cspan class=\"hljs-string\"\u003e'Jina relies heavily on multiprocessing.'\u003c/span\u003e),\n    Document(text=\u003cspan class=\"hljs-string\"\u003e'Jina is backed by Jina AI.'\u003c/span\u003e)])\n\nencoder.encode(docs=da)\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e doc \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e da:\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'\u003cspan class=\"hljs-subst\"\u003e{doc.embedding}\u003c/span\u003e'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c!-- \u003cscript src=\"https://gist.github.com/nan-wang/e4a872ec40803eabbbcc6618a4eccb1d.js\"\u003e\u003c/script\u003e --\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eTips\u003c/strong\u003e: If you want Jina to automatically install the extra dependencies, create a python virtual environment following the instructions at \u003ca href=\"https://docs.python.org/3/library/venv.html\"\u003evirtualenv\u003c/a\u003e and change Line 2 to\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-diff\"\u003e\u003cspan class=\"hljs-deletion\"\u003e- encoder = Executor.from_hub('jinahub://TransformerTorchEncoder')\u003c/span\u003e\n\u003cspan class=\"hljs-addition\"\u003e+ encoder = Executor.from_hub('jinahub://TransformerTorchEncoder', install_requirements=True)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNotice that we encode the question and the context passages with the same encoder. This might not be ideal because they usually have very different semantic meanings. For example, \u003cem\u003e“What is Jina?”\u003c/em\u003e has a very different meaning from \u003cem\u003e“Jina is a neural search framework”\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eA more reasonable approach would be to encode them differently. One of the SOTA models to achieve this is the encoder from \u003cstrong\u003eDeep Passage Retrieval (DPR)\u003c/strong\u003e, which has trained two BERT models jointly so that the question and the contexts are encoded differently but still into the same space. To choose whether the question or the context model, one can set the \u003ccode\u003eencoder_type\u003c/code\u003e argument. To try out DPR encoder, you just need to change the following line in the above code\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-diff\"\u003e\u003cspan class=\"hljs-deletion\"\u003e- encoder = Executor.from_hub('jinahub://TransformerTorchEncoder')\u003c/span\u003e\n\u003cspan class=\"hljs-addition\"\u003e+ encoder = Executor.from_hub('jinahub://DPRTextEncoder', uses_with={'encoder_type': 'context'})\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eTips\u003c/strong\u003e: Find more information at Jina Hub about \u003ca href=\"https://hub.jina.ai/executor/u9pqs8eb\"\u003eTransformerTorchEncoder\u003c/a\u003e and \u003ca href=\"https://hub.jina.ai/executor/awl0jxog\"\u003eDPRTextEncoder\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"vector-index\"\u003eVector Index\u003c/h3\u003e\n\u003cp\u003eFor comparing the vectors and retrieving the \u003cstrong\u003e\u003cem\u003etop K\u003c/em\u003e\u003c/strong\u003e nearest neighbors to the question vector, we can calculate the cosine similarities for each combination between the question and the passages. The complexity is \u003cem\u003e\u003cstrong\u003eO(n*log(n))\u003c/strong\u003e\u003c/em\u003e due to the requirement of retrieving top K results.\u003c/p\u003e\n\u003cp\u003eAlternatively, we usually resort to the \u003cstrong\u003eApproximate Nearest Neighbour (ANN)\u003c/strong\u003e algorithms to get an approximated result. In Jina Hub, you can find both implementations easily\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003eindexer = Executor.from_hub(\u003cspan class=\"hljs-string\"\u003e'jinahub://SimpleIndexer'\u003c/span\u003e)\nindexer.index(docs=da)\n\nq_da = DocumentArray([Document(text=\u003cspan class=\"hljs-string\"\u003e'What is Jina?'\u003c/span\u003e)])\n\nindexer.search(docs=q_da)\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e m \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e q_da[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].matches:\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'score: \u003cspan class=\"hljs-subst\"\u003e{m.scores[\u003cspan class=\"hljs-string\"\u003e\"cosine\"\u003c/span\u003e].value:\u003cspan class=\"hljs-number\"\u003e.4\u003c/span\u003ef}\u003c/span\u003e, text: \u003cspan class=\"hljs-subst\"\u003e{m.text}\u003c/span\u003e'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo try out the ANN indexer, you just need to change Line 1 as in the below code. Under the hood, we use an indexer based on \u003ca href=\"https://github.com/nmslib/hnswlib\"\u003eHnswlib\u003c/a\u003e, which is efficient and flexible in handling large amounts of vectors. The only bottleneck is memory usage because all the vectors are stored in memory in the format of float32.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-diff\"\u003e\u003cspan class=\"hljs-deletion\"\u003e- indexer = Executor.from_hub('jinahub://SimpleIndexer')\u003c/span\u003e\n\u003cspan class=\"hljs-addition\"\u003e+ indexer = Executor.from_hub('jinahub://U1MIndexer')\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eTips\u003c/strong\u003e: Find more information at Jina Hub about \u003ca href=\"https://hub.jina.ai/executor/zb38xlt4\"\u003eSimpleIndexer\u003c/a\u003e and \u003ca href=\"https://hub.jina.ai/executor/96v8ecrt\"\u003eU1MIndexer\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"reader\"\u003eReader\u003c/h2\u003e\n\u003cp\u003eThe reader extracts the exact answer from the context. Usually the contexts are long sentences containing multiple factoid and therefore we need the reader to extract the right answer based on the question. This is well studied as the machine reading comprehension problem. Given a question and the candidate contexts, the reader will return a score together with the most possible starting and ending position of the answers.\u003c/p\u003e\n\u003cp class=\"image-only\"\u003e\u003cspan class=\"image-wrapper\"\u003e\u003cimg src=\"/assets/images/blog/2021-11-29-odqa-part-1/reader.svg\" alt=\"\"\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eFor DPR we will use the pretrained reader model by Facebook Research for the ODQA problem. Under the hood it uses the BERT model to serve two purposes. Firstly, the representation of \u003ccode\u003e[CLS]\u003c/code\u003e token is used to calculate the relevant scores for each context to measure how relevant they are to the question. This part plays a role as a reranker with a cross-attention mechanism, which has more capacity than the dual encoder model. The downside is that this model is more expensive to compute and therefore it is only feasible to use on a small number of candidates.\u003c/p\u003e\n\u003cp\u003eThe second usage of the BERT representation is to calculate the probabilities of being a START or END position. Two hidden layers are appended for calculating the probability of being a START or an END position. All the tokens share the same layer weights.\u003c/p\u003e\n\u003cp class=\"image-only\"\u003e\u003cspan class=\"image-wrapper\"\u003e\u003cimg src=\"/assets/images/blog/2021-11-29-odqa-part-1/dpr_reader.svg\" alt=\"\"\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eDPRReaderRanker\u003c/code\u003e is available directly at the \u003ca href=\"https://hub.jina.ai/executor/gzhiwmgg\"\u003eJina Hub\u003c/a\u003e as well.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003eranker = Executor.from_hub(\u003cspan class=\"hljs-string\"\u003e'jinahub://DPRReaderRanker'\u003c/span\u003e)\nranker.rank(docs=q_da)\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e m \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e q_da[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].matches:\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'score: \u003cspan class=\"hljs-subst\"\u003e{m.scores[\u003cspan class=\"hljs-string\"\u003e\"relevance_score\"\u003c/span\u003e].value:\u003cspan class=\"hljs-number\"\u003e.4\u003c/span\u003ef}\u003c/span\u003e, text: \u003cspan class=\"hljs-subst\"\u003e{m.text}\u003c/span\u003e'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"put-them-all-together-in-a-flow\"\u003ePut them all together in a Flow\u003c/h2\u003e\n\u003cp\u003eNow we have gone through the components needed for building an ODQA system. The Jina Flow can help us line them together and serve as a service.\u003c/p\u003e\n\u003ch3 id=\"index\"\u003eIndex\u003c/h3\u003e\n\u003cp\u003eWe first create the Jina Flow and then index all the Documents so that the dense vector retriever can retrieve the context. The Documents are encoded by the \u003ccode\u003eDPRTextEncoder\u003c/code\u003e and stored by the \u003ccode\u003eSimpleIndexer\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e jina \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Document, DocumentArray, Flow\n\nda = DocumentArray([\n     Document(text=\u003cspan class=\"hljs-string\"\u003e'Jina is a neural search framework that empowers anyone to build SOTA and scalable deep learning search applications in minutes.'\u003c/span\u003e),\n     Document(text=\u003cspan class=\"hljs-string\"\u003e'Document, Executor, and Flow are the three fundamental concepts in Jina.'\u003c/span\u003e),\n     Document(text=\u003cspan class=\"hljs-string\"\u003e'Jina is backed by Jina AI and licensed under Apache-2.0.'\u003c/span\u003e)])\n\nf = (Flow()\n     .add(uses=\u003cspan class=\"hljs-string\"\u003e'jinahub+docker://DPRTextEncoder'\u003c/span\u003e, encoder_type=\u003cspan class=\"hljs-string\"\u003e'context'\u003c/span\u003e)\n     .add(uses=\u003cspan class=\"hljs-string\"\u003e'jinahub+docker://SimpleIndexer'\u003c/span\u003e))\n\n\u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e f:\n     f.post(on=\u003cspan class=\"hljs-string\"\u003e'/index'\u003c/span\u003e, inputs=da, show_progress=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"query\"\u003eQuery\u003c/h3\u003e\n\u003cp\u003eAfter indexing the Documents, we build a query Flow following the retriever-reader structure.\nWe query with a question in natural languages and get back the answers with relevance scores.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e jina \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Flow, Document, DocumentArray\n\nf = (Flow(expose_port=\u003cspan class=\"hljs-number\"\u003e45678\u003c/span\u003e)\n     .add(uses=\u003cspan class=\"hljs-string\"\u003e'jinahub+docker://DPRTextEncoder'\u003c/span\u003e, encoder_type=\u003cspan class=\"hljs-string\"\u003e'context'\u003c/span\u003e)\n     .add(uses=\u003cspan class=\"hljs-string\"\u003e'jinahub+docker://SimpleIndexer'\u003c/span\u003e)\n     .add(uses=\u003cspan class=\"hljs-string\"\u003e'jinahub+docker://DPRReaderRanker'\u003c/span\u003e))\n\nq_da = DocumentArray([Document(text=\u003cspan class=\"hljs-string\"\u003e'What is Jina?'\u003c/span\u003e)])\n\n\u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e f:\n    resp = f.post(on=\u003cspan class=\"hljs-string\"\u003e'/search'\u003c/span\u003e, inputs=q_da, return_results=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e doc \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e resp[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].docs:\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'question: \u003cspan class=\"hljs-subst\"\u003e{doc.text}\u003c/span\u003e'\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e m \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e doc.matches:\n        \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'score: \u003cspan class=\"hljs-subst\"\u003e{m.scores[\u003cspan class=\"hljs-string\"\u003e\"relevance_score\"\u003c/span\u003e].value:\u003cspan class=\"hljs-number\"\u003e.4\u003c/span\u003ef}\u003c/span\u003e, answer: \u003cspan class=\"hljs-subst\"\u003e{m.text}\u003c/span\u003e'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"host-a-restful-service\"\u003eHost a RESTful service\u003c/h3\u003e\n\u003cp\u003eFor hosting the service, we need to change the following line of codes,\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-diff\"\u003e\u003cspan class=\"hljs-deletion\"\u003e- with f:\u003c/span\u003e\n\u003cspan class=\"hljs-deletion\"\u003e-     f.post(on='/search', inputs=da, return_results=True)\u003c/span\u003e\n\u003cspan class=\"hljs-addition\"\u003e+ with f:\u003c/span\u003e\n\u003cspan class=\"hljs-addition\"\u003e+     f.cors = True\u003c/span\u003e\n\u003cspan class=\"hljs-addition\"\u003e+     f.protocol = 'http'\u003c/span\u003e\n\u003cspan class=\"hljs-addition\"\u003e+     f.block()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you can query directly via RESTful API. The Swagger docs UI is available at \u003ccode\u003ehttp://localhost:45678/docs\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-sh\"\u003ecurl --request POST \\\n     -d \u003cspan class=\"hljs-string\"\u003e'{\"data\": [\"text\": \"What is Jina?\"]}'\u003c/span\u003e \\\n     -H \u003cspan class=\"hljs-string\"\u003e'Content-Type: application/json'\u003c/span\u003e \n     \u003cspan class=\"hljs-string\"\u003e'http://localhost:45678/search'\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA more detailed documentation about the client-serving usage of Jina can be found at \u003ca href=\"https://docs.jina.ai/fundamentals/flow/flow-as-a-service/#flow-as-a-service\"\u003eJina Docs\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this post, we have a gentle walkthrough for building a two-stage ODQA system with Jina. Besides the retriever-reader pipeline, another choice is to replace the reader with a generator for generating answers based on the context.\nFurthermore, with a large language model such as \u003ccode\u003eGPT-3\u003c/code\u003e, it is also possible to generate answers directly from the question without retrieving any context. However, efficiency and precision are potential issues in practice.\u003c/p\u003e\n\u003cp\u003eIn the future posts, we will cover more about building ODQA systems with SOTA models in Jina.\nStay tuned and happy Searching!\u003c/p\u003e\n\u003ch2 id=\"reference\"\u003eReference\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2004.04906\"\u003eDense Passage Retrieval for Open-Domain Question Answering\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://lilianweng.github.io/lil-log/2020/10/29/open-domain-question-answering.html\"\u003eLil'Log\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","coverImage":"/assets/images/blog/2021-11-29-odqa-part-1/banner.jpg","tags":["odqa","qa chatbot"],"sanitize":false}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"2021-11-29-odqa-part-1"},"buildId":"TQ4qL1mPIDlUAIcAKpwVb","runtimeConfig":{},"isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
{"pageProps":{"post":{"title":"How to build a production-ready Financial Question Answering system with Jina and BERT","description":"Learn how to use Jina to build a Financial Question Answering search application","date":"2021-01-07T10:00:39.923Z","slug":"financial-qa-tutorial","author":"Bithiah Yuan","content":"<p>Learn how to use the neural search framework, <strong><a href=\"https://github.com/jina-ai/jina\">Jina</a></strong>, to build a <strong>Financial Question Answering (QA) search application</strong>\nusing the <a href=\"https://sites.google.com/view/fiqa/home\">FiQA</a> dataset, <a href=\"https://pytorch.org\">PyTorch</a>, and <a href=\"https://github.com/huggingface/transformers\">Hugging Face transformers</a>.</p>\n<p>For my master’s thesis, I built a Financial QA system using a fine-tuned BERT model called\n<a href=\"https://github.com/yuanbit/FinBERT-QA\">FinBERT-QA</a>. Motivated by the emerging demand in the financial industry for\nthe automatic analysis of unstructured and structured data at scale, <strong>QA systems can provide lucrative and competitive\nadvantages</strong> to companies by facilitating the decision making of financial advisers.</p>\n<p>The goal of my thesis was to search for a ranked list of relevant answer passages given a question.\nHere is an example of a financial domain-based question and a ground truth answer from the <a href=\"https://sites.google.com/view/fiqa/home\">FiQA</a> dataset:</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/sample-qa.png\" alt=\"performance\" width=\"450px\">\n<figcaption>Sample QA from the financial domain</figcaption>\n</figure>\n<p></p>\n<p>Here is a list of other questions from <a href=\"https://sites.google.com/view/fiqa/home\">FiQA</a>:</p>\n<pre><code class=\"hljs language-sql\">• What does it mean that stocks <span class=\"hljs-keyword\">are</span> “memoryless”?\n• What would a stock be worth if dividends did <span class=\"hljs-keyword\">not</span> exist?\n• What <span class=\"hljs-keyword\">are</span> the risks <span class=\"hljs-keyword\">of</span> Dividend<span class=\"hljs-operator\">-</span>yielding stocks?\n• Why do financial institutions charge so much <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">convert</span> currency?\n• <span class=\"hljs-keyword\">Is</span> there a candlestick <span class=\"hljs-keyword\">pattern</span> that guarantees <span class=\"hljs-keyword\">any</span> kind <span class=\"hljs-keyword\">of</span> future profit?\n• <span class=\"hljs-number\">15</span> <span class=\"hljs-keyword\">year</span> mortgage vs <span class=\"hljs-number\">30</span> <span class=\"hljs-keyword\">year</span> paid off <span class=\"hljs-keyword\">in</span> <span class=\"hljs-number\">15</span>\n• Why <span class=\"hljs-keyword\">is</span> it rational <span class=\"hljs-keyword\">to</span> pay <span class=\"hljs-keyword\">out</span> a dividend?\n• Why do companies have a fiscal <span class=\"hljs-keyword\">year</span> different <span class=\"hljs-keyword\">from</span> the calendar <span class=\"hljs-keyword\">year</span>?\n• What should I look <span class=\"hljs-keyword\">at</span> before investing <span class=\"hljs-keyword\">in</span> a <span class=\"hljs-keyword\">start</span><span class=\"hljs-operator\">-</span>up?\n• <span class=\"hljs-keyword\">Where</span> do <span class=\"hljs-keyword\">large</span> corporations store their massive amounts <span class=\"hljs-keyword\">of</span> cash?\n</code></pre>\n<p>Financial QA is <strong>hard</strong> because the vocabularies are context specific, for example, a machine would\nhave a hard time understanding what an <em>ETF</em> is. Nevertheless, <strong>with the power of BERT, I improved the state-of-the-art (SOTA) results by an average of 19% on three\nevaluation metrics (Precision, MRR, NDCG)</strong>.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/model-performance.png\" alt=\"performance\" width=\"600px\">\n<figcaption>Evaluation results from <a href=\"https://github.com/yuanbit/FinBERT-QA\">FinBERT-QA</a></figcaption>\n</figure>\n<p></p>\n<p>Even though my thesis was about QA in the financial domain, the approach that I have used can be applied to a\n<a href=\"https://github.com/microsoft/MSMARCO-Passage-Ranking\">general QA dataset</a> or QA in other domains such as\n<a href=\"https://github.com/shuzi/insuranceQA\">insurance</a>.</p>\n<p>After finishing my thesis, I realized that <strong>just having a model and SOTA results is not good enough</strong> because there\nwas a gap between my research and business needs. This was when I discovered <strong>Jina, a framework designed to\nhelp me bridge this gap</strong>. To help people better understand Jina, I prepared this tutorial to demonstrate how\nI used Jina to easily <strong>transform my research into a production-ready system</strong>.</p>\n<h2 id=\"user-content-table-of-contents\">Table of Contents</h2>\n<ul>\n<li><a href=\"#table-of-contents\">Table of Contents</a></li>\n<li><a href=\"#background\">Background</a>\n<ul>\n<li><a href=\"#what-is-jina\">What is Jina?</a></li>\n<li><a href=\"#financial-qa-with-bert\">Financial QA with BERT</a></li>\n</ul>\n</li>\n<li><a href=\"#why-jina\">Why Jina?</a>\n<ul>\n<li><a href=\"#jina-as-a-bridge-between-research-and-industry\">Jina as a bridge between research and industry</a></li>\n</ul>\n</li>\n<li><a href=\"#tutorial\">Tutorial</a>\n<ul>\n<li><a href=\"#set-up\">Set up</a></li>\n<li><a href=\"#index-flow\">Index Flow</a>\n<ul>\n<li><a href=\"#step-1-define-our-data\">Step 1. Define our data</a></li>\n<li><a href=\"#step-2-encode-answer-passages\">Step 2. Encode Answer Passages</a></li>\n<li><a href=\"#step-3-indexing\">Step 3. Indexing</a></li>\n<li><a href=\"#build-an-indexer-application\">Build an Indexer Application</a></li>\n</ul>\n</li>\n<li><a href=\"#query-flow\">Query Flow</a>\n<ul>\n<li><a href=\"#step-1-encode-question\">Step 1. Encode Question</a></li>\n<li><a href=\"#step-2-search-indexes\">Step 2. Search Indexes</a></li>\n<li><a href=\"#step-3-reranking\">Step 3. Reranking</a></li>\n<li><a href=\"#build-a-custom-executor\">Build a Custom Executor</a></li>\n<li><a href=\"#build-a-search-application\">Build a Search Application</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#summary\">Summary</a></li>\n<li><a href=\"#next-step-evaluation\">Next Step: Evaluation</a></li>\n<li><a href=\"#learn-more\">Learn More</a></li>\n<li><a href=\"#community\">Community</a></li>\n</ul>\n<h2 id=\"user-content-background\">Background</h2>\n<h3 id=\"user-content-what-is-jina\">What is Jina?</h3>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/jina_banner_new.png\" width=\"500\"></span>\n</p>\n<p>Open-source deep learning frameworks such as TensorFlow and PyTorch provide building blocks for designing and quickly implementing\nneural network-based applications through a high level programming interface.</p>\n<p>Similarly, <strong>Jina</strong> is an <strong>open-source neural search framework</strong> that offers the building blocks for designing and implementing <strong>neural network-based\nsearch applications</strong>.</p>\n<p>Co-founded by the creator of <a href=\"https://github.com/hanxiao/bert-as-service\">bert-as-service</a> and\n<a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST</a>, Jina enables developers to build\n<strong>production-ready cloud-native search systems</strong> using\n<strong>SOTA pre-trained deep learning models</strong>, in which each component of the system is a <strong>microservice</strong> that can be deployed, scaled, and maintained independently.</p>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/blog/financial-qa/cloud.png\" width=\"350\"></span>\n</p>\n<p>If you come from a data science or academic background like me, the terms <strong>cloud-native</strong> and <strong>microservices</strong> may sound\ndaunting. That's why we will learn by example in this tutorial and use the NLP task, Financial QA, to familiarize ourselves\nwith Jina's core concepts!</p>\n<h3 id=\"user-content-financial-qa-with-bert\">Financial QA with BERT</h3>\n<p>Before we jump into the tutorial, let's first understand how to build a QA system with BERT. Our goal is to\nsearch for the top-k most relevant answer passages when given a question from task 2 of the <a href=\"https://sites.google.com/view/fiqa/home\">FiQA</a> dataset.</p>\n<p>In 2018, Google's pre-trained BERT models, used for transfer learning, shook the NLP world and achieved the SOTA\nresults on numerous tasks, marking NLP's <a href=\"https://ruder.io/nlp-imagenet/\">ImageNet moment</a>.</p>\n<p>What is neat about BERT is that we can fine-tune a pre-trained BERT model on our QA task by simply transforming\nit into a <strong>binary classification task</strong>, where the input is the <strong>concatenation of a question and an answer</strong> and the\noutput is a binary label indicating the <strong>relevancy score</strong> of the QA pair. We can then take the softmax scores of\neach QA pair to get a probability of relevancy and rank these scores.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/BERT-QA.png\" width=\"400\">\n<figcaption>Fine-tuning method for our QA task</figcaption>\n</figure>\n<p></p>\n<p>The <a href=\"https://sites.google.com/view/fiqa/home\">FiQA</a> dataset has roughly 6,000 questions and 57,000 answers. Instead of\ncomputing a probability for each question 57,000 times, we can adapt a <a href=\"https://arxiv.org/pdf/1901.04085.pdf\">passage reranking</a>\napproach. We first use a <strong>Retriever</strong> to return the top-50 candidate answers for each question,\nand then use <strong>FinBERT-QA</strong>, a BERT-based model fine-tuned on the <a href=\"https://sites.google.com/view/fiqa/home\">FiQA</a> dataset\nas a <strong>Reranker</strong> to compute the relevancy scores and rerank the top-50 QA pairs to get the top-10 answers.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/qa-pipeline-simple.png\" width=\"1000\">\n<figcaption>QA pipeline with reranking</figcaption>\n</figure>\n<p></p>\n<p>If you are interested in the details of my thesis, you can learn more <a href=\"https://github.com/yuanbit/FinBERT-QA\">here</a>.</p>\n<h2 id=\"user-content-why-jina\">Why Jina?</h2>\n<p>Why is having the SOTA model and results is not good enough?</p>\n<h3 id=\"user-content-jina-as-a-bridge-between-research-and-industry\">Jina as a bridge between research and industry</h3>\n<p>The motivation behind my research was to be able to help financial advisor answer questions\nfrom large-scale reports. However, the way I implemented the QA pipeline is not reusable and it won't scale\nto business demands. <strong>By industry standards, it is not production-ready.</strong></p>\n<p>Since <strong>Jina enables us to build cloud-native systems</strong>, which embrace\nmicroservices, instead of wrapping my entire pipeline in a single Docker container, Jina will break down the pipeline\ninto components (preprocessor, encoder, indexer, etc.). Moreover, each of these components will be a microservice in its own isolated Docker\ncontainer managed by the <a href=\"https://docs.jina.ai/chapters/flow/index.html\">Flow API</a>.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/cloud2.svg\" width=\"350\">\n<figcaption>Illustration from <a href=\"https://www.manypixels.co/gallery/\">manypixels</a></figcaption>\n</figure>\n<p></p>\n<p>For those of you new to cloud-native concepts, you can think of a microservice as an independent component of your\napplication, for example, using FinBERT-QA to encode our questions and answers. You can then create multiple independent components\nor microservices to construct an application like a BERT-powered QA system. Since each of the components of the application can be deployed independently,\nthey can also scale individually and respond to rapid changes and business needs.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/business.svg\" width=\"350\">\n<figcaption>Illustration from <a href=\"https://www.manypixels.co/gallery/\">manypixels</a></figcaption>\n</figure>\n<p></p>\n<p>Being cloud-native is a modern design that more and more businesses are adapting to because it can help them save resources\nand grow. However, designing such systems is not easy. We need to consider many principles, patterns and best practices,\nfor example, how will the each component communicate with each other? How can they work in parallel? Luckily, instead of starting\nfrom scratch, <strong>Jina does all the hard work for us by providing us the building blocks so that we can easily construct\na cloud-native BERT-powered QA system using an reranking approach that is ready to serve in production!</strong></p>\n<h2 id=\"user-content-tutorial\">Tutorial</h2>\n<p>Now that we have an overview, let's learn how to build a production-ready Financial QA system using the reranking approach and\ndive deeper into some new Jina terminologies. We will use <a href=\"https://github.com/ProsusAI/finBERT\">FinBERT</a> to encode our\nquestions and answer passages into embeddings and <a href=\"https://github.com/yuanbit/FinBERT-QA\">FinBERT-QA</a> to rerank\nthe top-50 answer matches.</p>\n<p><strong>The final code of this tutorial can be found <a href=\"https://github.com/yuanbit/jina-financial-qa-search\">here</a>.</strong></p>\n<h3 id=\"user-content-set-up\">Set up</h3>\n<p><strong>Clone the repository</strong> that we will be working together with here:</p>\n<pre><code class=\"hljs language-bash\">git <span class=\"hljs-built_in\">clone</span> https://github.com/yuanbit/jina-financial-qa-search-template.git\n</code></pre>\n<p>We will use <code>financial-qa-search/</code> as our working directory.</p>\n<p><strong>Install the requirements</strong></p>\n<pre><code class=\"hljs\">pip install -r requirements.txt\n</code></pre>\n<p><strong>Download data and model</strong></p>\n<pre><code class=\"hljs\">bash get_data.sh\n</code></pre>\n<p>For this tutorial, we won't be searching through all 57,000 answer passages from the\n<a href=\"https://sites.google.com/view/fiqa/home\">FiQA</a> dataset. We will work with a sample dataset called <code>test_answers.csv</code>,\ncontaining about 800 answer passages. If you want to experiment with the full dataset, you can use <code>answer_collection.tsv</code>.</p>\n<p><strong>Flows</strong></p>\n<p>In Jina, we will build a Financial QA system with two pipelines, one for indexing our answer passages and\nthe other for querying. These pipelines are called <strong>Flows</strong>, which also serve to manage the state and context\nof the microservices as well as orchestrating them. Let's see what an overview of\nthe <strong>Index Flow</strong> and <strong>Query Flow</strong>, you can click on the images to see the details:</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<a href=\"https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/index-flow.png\">\n<img src=\"/assets/images/blog/financial-qa/index-flow.png\" width=\"1000\">\n</a>\n<figcaption>Index Flow</figcaption>\n</figure>\n<p></p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<a href=\"https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/query-flow.png\">\n<img src=\"/assets/images/blog/financial-qa/query-flow.png\" width=\"1000\">\n</a>\n<figcaption>Query Flow</figcaption>\n</figure>\n<p></p>\n<p>To understand these Flows, let's start with the <strong>Index Flow</strong> and look into the individual components one by one.</p>\n<h3 id=\"user-content-index-flow\">Index Flow</h3>\n<p>The main idea behind the Index Flow is to use a pre-trained BERT model to encode all of our answer\npassages into embeddings then indexing these embeddings so that they can be searched in the Query Flow.</p>\n<h4 id=\"user-content-step-1-define-our-data\">Step 1. Define our data</h4>\n<p>We want to index a subset of  the answer passages from the FiQA dataset, <code>dataset/test_answers.csv</code>:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-number\">398960</span>\tFrom  http://financial-dictionary.thefreedictionary.com/Business+Fundamentals  The  facts  that  affect  a  company<span class=\"hljs-string\">'s      underlying  value.  Examples  of  business      fundamentals  include  debt,  cash  flow,      supply  of  and  demand  for  the  company'</span>s      products,  <span class=\"hljs-keyword\">and</span>  so  forth.  For  instance,      <span class=\"hljs-keyword\">if</span>  a  company  does  <span class=\"hljs-keyword\">not</span>  have  a      sufficient  supply  of  products,  it  will      fail.  Likewise,  demand  <span class=\"hljs-keyword\">for</span>  the  product      must  remain  at  a  certain  level  <span class=\"hljs-keyword\">in</span>      order  <span class=\"hljs-keyword\">for</span>  it  to  be  successful.  Strong      business  fundamentals  are  considered      essential  <span class=\"hljs-keyword\">for</span>  long-term  success  <span class=\"hljs-keyword\">and</span>      stability.  See  also:  Value  Investing,      Fundamental  Analysis.  For  a  stock  the  basic  fundamentals  are  the  second  column  of  numbers  you  see  on  the  google  finance  summary  page,    P/E  ratio,  div/yeild,  EPS,  shares,  beta.      For  the  company  itself  it<span class=\"hljs-string\">'s  generally  the  stuff  on  the  '</span>financials<span class=\"hljs-string\">'  link    (e.g.  things  in  the  quarterly  and  annual  report,    debt,  liabilities,  assets,  earnings,  profit  etc.\n19183\tIf  your  sole  proprietorship  losses  exceed  all  other  sources  of  taxable  income,  then  you  have  what'</span>s  called  a  Net  Operating  Loss  (NOL).  You  will  have  the  option  to  <span class=\"hljs-string\">\"carry  back\"</span>  <span class=\"hljs-keyword\">and</span>  amend  a  <span class=\"hljs-keyword\">return</span>  you  filed  <span class=\"hljs-keyword\">in</span>  the  last  <span class=\"hljs-number\">2</span>  years  where  you  owed  tax,  <span class=\"hljs-keyword\">or</span>  you  can  <span class=\"hljs-string\">\"carry  forward\"</span>  the  losses  <span class=\"hljs-keyword\">and</span>  decrease  your  taxes  <span class=\"hljs-keyword\">in</span>  a  future  year,  up  to  <span class=\"hljs-number\">20</span>  years  <span class=\"hljs-keyword\">in</span>  the  future.  For  more  information  see  the  IRS  links  <span class=\"hljs-keyword\">for</span>  NOL.  Note:  it<span class=\"hljs-string\">'s  important  to  make  sure  you  file  the  NOL  correctly  so  I'</span>d  advise  speaking  <span class=\"hljs-keyword\">with</span>  an  accountant.  (Especially  <span class=\"hljs-keyword\">if</span>  the  loss  <span class=\"hljs-keyword\">is</span>  greater  than  the  cost  of  the  accountant...)\n<span class=\"hljs-number\">327002</span>\tTo  be  deductible,  a  business  expense  must  be  both  ordinary  <span class=\"hljs-keyword\">and</span>  necessary.  An  ordinary  expense  <span class=\"hljs-keyword\">is</span>  one  that  <span class=\"hljs-keyword\">is</span>  common  <span class=\"hljs-keyword\">and</span>  accepted  <span class=\"hljs-keyword\">in</span>  your  trade  <span class=\"hljs-keyword\">or</span>  business.  A  necessary  expense  <span class=\"hljs-keyword\">is</span>  one  that  <span class=\"hljs-keyword\">is</span>  helpful  <span class=\"hljs-keyword\">and</span>  appropriate  <span class=\"hljs-keyword\">for</span>  your  trade  <span class=\"hljs-keyword\">or</span>  business.  An  expense  does  <span class=\"hljs-keyword\">not</span>  have  to  be  indispensable  to  be  considered  necessary.    (IRS,  Deducting  Business  Expenses)  It  seems  to  me  yo<span class=\"hljs-string\">u'd  have  a  hard  time  convincing  an  auditor  that  this  is  the  case.    Since  business  don'</span>t  commonly  own  cars  <span class=\"hljs-keyword\">for</span>  the  sole  purpose  of  housing  $<span class=\"hljs-number\">25</span>  computers,  yo<span class=\"hljs-string\">u'd  have  trouble  with  the  \"ordinary\"  test.    And  since  there  are  lots  of  other  ways  to  house  a  computer  other  than  a  car,  \"necessary\"  seems  problematic  also.\n</span></code></pre>\n<p>Our dataset consists of a column of answer id and text, which we will denote as docid and doc respectively in this tutorial.\nIn order to index our data, we need to first define it in a Jina data type called <strong>Document</strong>.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/index-flow-step1.png\" width=\"400\">\n<figcaption>Index Flow - Step 1</figcaption>\n</figure>\n<p></p>\n<p>In programming languages there are data types such as int, float, boolean, and more. In NumPy, TensorFlow, and PyTorch,\nwe manipulate and pass around objects such as ndarray and tensor, which are referred to as <strong>primitive data types</strong>.\nSimilarly, a <strong>Document</strong> is a Jina-specific data type for representing data.</p>\n<p><strong>Defining our data in a Document</strong></p>\n<p>In our project directory <code>financial-qa-search/</code> the <code>app.py</code> file consists of the Financial QA search application\nthat we will build.  Notice that we set our data path in the <code>config</code> function as follows:</p>\n\n<p>You can change the path to <code>answer_collection.tsv</code> to index with the full dataset.</p>\n<p>Let's first make sure we import <code>Document</code> from jina:</p>\n\n<p>After the <code>config</code> function, let's create a Python generator and define the Document to contain the id and text\ncorresponding to the answer passages:</p>\n\n<p>A Document is a high-level way for us to <strong>define and view the contents stored in Protobuf</strong>, which is what Jina uses to\n<strong>enable the microservices in the Flow to communicate with each other</strong>. It is like an envelope\ncontaining our data and is used to send messages between the microservices of our Flow. Instead of directly\ndealing with Protobuf, which serializes our data into bytes, we can simply print our Document and see that a single answer\npassage will look as follows:</p>\n<pre><code class=\"hljs language-swift\">id: <span class=\"hljs-string\">\"13755c6081bebe1a\"</span>\nmime_type: <span class=\"hljs-string\">\"text/plain\"</span>\ntags {\n  fields {\n    key: <span class=\"hljs-string\">\"id\"</span>\n    value {\n      number_value: <span class=\"hljs-number\">398960.0</span>\n    }\n  }\n}\ntext: <span class=\"hljs-string\">\"From  http://financial-dictionary.thefreedictionary.com/Business+Fundamentals  The  facts  that  affect  a  \ncompany<span class=\"hljs-subst\">\\'</span>s underlying  value. Examples  of  business fundamentals  include  debt,  cash  flow, supply  of  and  demand  \nfor  the  company<span class=\"hljs-subst\">\\'</span>s      products,  and  so  forth.  For  instance, if  a  company  does  not  have  a sufficient  \nsupply  of  products,  it  will      fail.  Likewise,  demand  for  the  product      must  remain  at  a  certain  \nlevel  in      order  for  it  to  be  successful.  Strong      business  fundamentals  are  considered essential  for  \nlong-term  success  and      stability.  See  also:  Value  Investing, Fundamental  Analysis.  For  a  stock  the  basic\nfundamentals  are  the  second  column  of  numbers  you  see  on  the  google  finance  summary  page, P/E  ratio,  \ndiv/yeild,  EPS,  shares,  beta.      For  the  company  itself  it<span class=\"hljs-subst\">\\'</span>s  generally  the  stuff  on  the  <span class=\"hljs-subst\">\\'</span>financials<span class=\"hljs-subst\">\\'</span>  \nlink    (e.g.  things  in  the  quarterly  and  annual  report,    debt,  liabilities,  assets,  earnings,  profit  etc.\"</span>\n</code></pre>\n<p><strong>As we move along the Index Flow, the contents of the Document will be changed</strong>, for example, we can see in the Index Flow that\nthe embeddings of the answer passages are added to the Document after the encoding step.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/index-flow-step2-2.png\" width=\"500\">\n<figcaption>Embeddings of the answer passages are added to the Document after the encoding step1</figcaption>\n</figure>\n<p></p>\n<p>The encoding step uses an <strong>Executor</strong>, namely the <strong>Encoder</strong>. Let's understand this more next.</p>\n<h4 id=\"user-content-step-2-encode-answer-passages\">Step 2. Encode Answer Passages</h4>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/blog/financial-qa/Encoder.png\" width=\"300\"></span>\n</p>\n<p>After defining the Document for the <strong>Index Flow</strong>, the next step is to encode the answer text into embeddings\nusing a pre-trained BERT model. The logic that does the encoding is called an <strong>Encoder</strong>, which is part of Jina's family\nof <strong>Executors</strong>.</p>\n<p>We will look at other Executors later and only focus on the Encoder for now. Instead using TensorFlow\nor PyTorch with the combination of Hugging Face transformers and implementing the Encoder ourselves, we can simply take advantage\nof <a href=\"https://github.com/jina-ai/jina-hub\">Jina Hub</a>, an <strong>open-registry for hosting Jina Executors via container images</strong>.</p>\n<p>There are all kinds of Encoders and other types of Executors in Jina Hub for different tasks and data types\n(e.g. image, video, audio, multimodal), allowing us to <strong>ship and exchange reusable component and build various\ndeep learning-based search engines, e.g. text-image, cross-modal, and multi-modal searches.</strong>\nSince our task is a text-to-text search, we will use the\n<a href=\"https://github.com/jina-ai/jina-hub/tree/master/encoders/nlp/TransformerTorchEncoder\">TransformerTorchEncoder</a> for this tutorial.</p>\n<p>Before we talk about how to use the Encoder in our Index Flow, let's understand three more important Jina concepts in this\nstep:</p>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/blog/financial-qa/Driver.png\" width=\"300\"></span>\n</p>\n<ul>\n<li><strong>Driver:</strong> Recall Jina uses Protobuf to send messages between the microservices in the Flow, which are in the form of bytes.\nWe would have a problem if we were to pass the Document directly to the Encoder because the Encoder needs the\nanswer text as input instead of bytes. Instead of dealing directly with Protobuf, Jina uses <strong>Drivers</strong> to <strong>translate\ndata for an Executor</strong>, so that we only need to work with data types that we are familiar with (e.g. text, image, np,array, etc...).\n<strong>The Driver interprets messages in the Flow and passes the appropriate data to the Executor.</strong></li>\n</ul>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/index-flow-step2.png\" width=\"550\">\n<figcaption>Encoder - the Driver receives the Document in byes and passes the text to the Encoder. The Encoder outputs the embeddings of the text and the Driver adds them to the Document.</figcaption>\n</figure>\n<p></p>\nFor example, in the encoding step, the Driver receives the Document in bytes, interprets it as a Document, and passes the text in the Document to the Encoder.\nAfter the Encoder outputs the embeddings for the corresponding text, the Driver \nagain interprets the embeddings, and adds them to the Document. The Document below shows how it has be transformed by\nthe Driver in the encoding step and will serve as the input for the next indexing step.\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/index-flow-step2-2.png\" width=\"500\">\n<figcaption>The Driver transformed the Document by adding the embeddings in the encoding step.</figcaption>\n</figure>\n<p></p>\n<ul>\n<li><strong>Pea:</strong> Since an Executor needs a Driver to be able to process our data, they are both necessary components of a\nmicroservice in the Flow. Therefore, we use a <strong>Pea</strong> to wrap the Executor and Driver together to get our <strong>Encoder Microservice</strong>.\nThe Pea is, therefore, a <strong>microservice</strong> that constantly listens for incoming messages from the gateway or other Peas in\nthe Flow and calls the Driver when it receives a message. As a microservice, <strong>Peas can also run in Docker, containing all dependencies and context in one place.</strong></li>\n</ul>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/blog/financial-qa/Pea.png\" width=\"300\"></span>\n</p>\n<ul>\n<li>\n<p><strong>Pod:</strong> To optimize our neural search application, <strong>Jina provides parallelization out of the box.</strong> Instead of having a\nsingle Encoder, we can split it into <strong>multiple processes</strong>. The visualization of the Encoding step shows the Encoder being split into three\nprocesses with each process wrapped by a Pea.</p>\n<p><strong>In order for our multiple Encoder microservices to behave functionally as one Encoder, we wrap the group of homogeneous (identical) Peas in a Pod</strong>.\nThe Pod is, therefore, a <strong>group of homogeneous microservices</strong> that is also responsible for load balancing, further control and context management.\nThe beauty about this design is that a Pod can either run on the local host or on different computers over a network,\nmaking our application <strong>distributed, efficient, and scalable</strong>.</p>\n</li>\n</ul>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/blog/financial-qa/Pod.png\" width=\"300\"></span>\n</p>\n<p>Now that we understand these foundational concepts, <strong>how do we create a Pod for the Encoder?</strong></p>\n<p>It may all sound extremely\ncomplicated, but with the building blocks provided by Jina we can <strong>(1) design an Index Flow and (2) create an Encoder\nPod with two simple YAML files.</strong> These YAML files will allow us to customize our neural search application without\ntouching the core of Jina's code.</p>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/blog/financial-qa/YAML.png\" width=\"300\"></span>\n</p>\n<p><strong>I. Create a Pod for the Encoder</strong></p>\n<p>Let's first create a file <code>encode.yml</code> inside the folder called <code>pods</code>. In <code>encode.yml</code>\nwe first specify the name of the Encoder we want to use from Jina Hub <code>TransformerTorchEncoder</code>. We can\nchoose the model we want to use, in our case we use <a href=\"https://github.com/ProsusAI/finBERT\">FinBERT</a>, which further\npre-trained <code>bert-base-uncased</code> on a large financial corpus. Since <code>TransformerTorchEncoder</code> was implemented\nusing Hugging Face transformers, you can also directly use the model by specifying its name if it is available on\nthe <a href=\"https://huggingface.co/docs\">Hugging Face Model Hub</a>. We can also include other hyperparameters such as the\nmaximum sequence length or pooling strategy.</p>\n\n<p>Simple as that! 🐣 <strong>We just created a deep learning-based Encoder microservice ready to be parallelized!</strong>\nThe <code>pods</code> folder will also be the home to other Pods that we will need, which will\nalso be defined using YAML files.</p>\n<p><strong>II. Add the Encoder to the Index Flow</strong></p>\n<p>Now that we have our Encoder ready, let's put it in our Index Flow. Let's create a file <code>index.yml</code> inside a\nfolder called <code>flows</code>. In <code>index.yml</code>, we specify our first Pod in the Index Flow which is the <code>encoder</code> by\ngiving the path to our <code>pods/encode.yml</code> file. We can specify how many processes we want to split the Encoder into\nby using the <code>parallel</code> parameter. This will be an environment variable specified in <code>app.py</code>, which we will\nlook at in the end. <code>parallel</code> also <strong>determines how many Peas we will have in each Pod.</strong></p>\n\n<p>Well done! 💪 You've just created a pipeline for deep learning-powered microservices! Next, let's finish the design of the Index\nFlow by adding another Pod containing the Indexer.</p>\n<h4 id=\"user-content-step-3-indexing\">Step 3. Indexing</h4>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/blog/financial-qa/Indexer.png\" width=\"300\"></span>\n</p>\n<p>After obtaining the embeddings for the answer passages, we will create another Executor called the <strong>Indexer</strong>\nto store our data so that they can be retrieved in query time. Similar to the previous step, the Driver receives the\nDocument and passes the <code>docid</code>, <code>doc</code>, and <code>embeddings</code> to the Indexer.</p>\n<p>We will use the <strong>Compound Indexer</strong>,\nwhich acts as a single indexer using both the <strong>(1) Vector</strong> and <strong>(2) Key-Value Indexers</strong> from Jina Hub:</p>\n<ol>\n<li>\n<p><strong>Vector Indexer:</strong> Stores the answer embeddings and is queried by the question embedding to retrieve\nthe closest answer embeddings using the k-nearest neighbors algorithm.</p>\n</li>\n<li>\n<p><strong>Key-Value (KV) Indexer:</strong> Stores the Document data (text, blob, metadata) and is queried by the Document id (normally\nextracted from the Vector Indexer) to retrieve the information of the data such as answer id and text.</p>\n</li>\n</ol>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/index-flow-step3.png\" width=\"600\">\n<figcaption>The Indexer will store our data so that they can be retrieved in query time</figcaption>\n</figure>\n<p></p>\n<p>We again wrap the Driver and Indexer in a Pea, group identical Peas in a Pod, and define them using YAML files.</p>\n<p><strong>I. Create a Pod for the Indexer</strong></p>\n<p>Let's create the file <code>pods/doc.yml</code> and define our compound indexer as <code>!CompoundIndexer</code> with the components\n<code>!NumpyIndexer</code> which is the Vector Indexer and <code>!BinaryPbIndexer</code> which is the KV Indexer. The indexed data\nwill be stored in <code>vec.gz</code> and <code>doc.gz</code> respectively. The <code>workspace</code>\nis the directory where the indexes will be stored, which will be inside our working directory.</p>\n\n<p><strong>II. Add the Indexer to the Index Flow</strong></p>\n<p>Now let's go back to <code>flows/index.yml</code> and add our Indexer to the Index Flow as <code>doc_indexer</code>. If our data is\nbig, we can also add sharding to our application for optimization. This will also be used as an environment variable\nin <code>app.py</code>, which we will see later.</p>\n\n<p>Great job! 👏 You have just designed a cloud-native pipeline for indexing financial answer passages! We can\nalso use Jina's <a href=\"https://docs.jina.ai/chapters/flow/index.html\">Flow API</a> to\nvisualize the Index Flow. First let's set our environment variables in the terminal for parallel and shards:</p>\n<pre><code class=\"hljs language-ini\">export <span class=\"hljs-attr\">JINA_PARALLEL</span>=<span class=\"hljs-string\">'1'</span>\nexport <span class=\"hljs-attr\">JINA_SHARDS</span>=<span class=\"hljs-string\">'1'</span>\n</code></pre>\n<p>Next, let's open a <code>jupyter notebook</code> in our working directory and do the following:</p>\n\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/index-flow-jina.png\" width=\"1000\">\nIndex Flow visualzation\n</figure>\n<p></p>\n<p>Here we see our Index Flow with two Pods - the Encoder, <code>encoder</code> and Indexer, <code>doc_indexer</code>.</p>\n<h4 id=\"user-content-build-an-indexer-application\">Build an Indexer Application</h4>\n<p>Let's see how we can use the Index Flow as our application. In <code>app.py</code>, we can change\n<code>parallel</code> in the <code>config</code> function to indicate how many Peas (processes)\nwe want to split each microservice in for each Pod. We can also change <code>shards</code>\nto indicate parallelization during the indexing step. We will leave both of them unchanged for now.\nThis means that we will only have one Pea in each Pod.</p>\n<p>Let's first import <code>Flow</code> from Jina's <a href=\"https://docs.jina.ai/chapters/flow/index.html\">Flow API</a>:</p>\n\n<p>After the <code>index_generator</code> function that we added in <a href=\"#step-1-define-our-data\">Step 1. Define our data</a>,\nlet's add the <code>index</code> function which will first load the Index Flow that we have created in <code>flows/index.yml</code>\nand pass the input Document from <code>index_generator</code> to the flow. We set our <code>batch_size=16</code> for encoding\nthe answer passages into embeddings.</p>\n\n<p>We are now ready to index our data. In the our working directory run:</p>\n<pre><code class=\"hljs language-perl\">python app.py <span class=\"hljs-keyword\">index</span>\n</code></pre>\n<p><a href=\"https://asciinema.org/a/RDQvKPeibRRURYtpQWqmkCUsH\"><img src=\"https://asciinema.org/a/RDQvKPeibRRURYtpQWqmkCUsH.svg\" alt=\"asciicast\"></a></p>\n<p>At the end you will see the following:</p>\n<pre><code class=\"hljs language-ruby\">✅ done <span class=\"hljs-keyword\">in</span> ⏱ <span class=\"hljs-number\">1</span> minute <span class=\"hljs-keyword\">and</span> <span class=\"hljs-number\">54</span> seconds 🐎 <span class=\"hljs-number\">7.7</span>/s\n        gateway<span class=\"hljs-variable\">@18904</span>[S]<span class=\"hljs-symbol\">:terminated</span>\n    doc_indexer<span class=\"hljs-variable\">@18903</span>[I]<span class=\"hljs-symbol\">:recv</span> ControlRequest from ctl▸doc_indexer▸⚐\n    doc_indexer<span class=\"hljs-variable\">@18903</span>[I]<span class=\"hljs-symbol\">:Terminating</span> loop requested by terminate signal RequestLoopEnd()\n    doc_indexer<span class=\"hljs-variable\">@18903</span>[I]<span class=\"hljs-symbol\">:</span><span class=\"hljs-comment\">#sent: 56 #recv: 56 sent_size: 1.7 MB recv_size: 1.7 MB</span>\n    doc_indexer<span class=\"hljs-variable\">@18903</span>[I]<span class=\"hljs-symbol\">:request</span> loop ended, tearing down ...\n    doc_indexer<span class=\"hljs-variable\">@18903</span>[I]<span class=\"hljs-symbol\">:indexer</span> <span class=\"hljs-symbol\">size:</span> <span class=\"hljs-number\">865</span> physical <span class=\"hljs-symbol\">size:</span> <span class=\"hljs-number\">3.1</span> MB\n    doc_indexer<span class=\"hljs-variable\">@18903</span>[S]<span class=\"hljs-symbol\">:artifacts</span> of this executor (vecidx) is persisted to ./workspace/doc_compound_indexer-<span class=\"hljs-number\">0</span>/vecidx.bin\n    doc_indexer<span class=\"hljs-variable\">@18903</span>[I]<span class=\"hljs-symbol\">:indexer</span> <span class=\"hljs-symbol\">size:</span> <span class=\"hljs-number\">865</span> physical <span class=\"hljs-symbol\">size:</span> <span class=\"hljs-number\">3.2</span> MB\n    doc_indexer<span class=\"hljs-variable\">@18903</span>[S]<span class=\"hljs-symbol\">:artifacts</span> of this executor (docidx) is persisted to ./workspace/doc_compound_indexer-<span class=\"hljs-number\">0</span>/docidx.bin\n</code></pre>\n<p>Hooray 🙌 we finished the first part of our application! The embedding indexes and Document data will be stored in a directory called <code>workspace</code>.</p>\n<h3 id=\"user-content-query-flow\">Query Flow</h3>\n<p>After indexing our data, we need to create a <strong>Query Flow</strong>. The main idea behind the Query Flow is to use the\nsame BERT-based model to <strong>encode a given question into an embedding</strong> and use the Indexer to <strong>search for the most\nsimilar answer embeddings</strong>. To further improve the search results, we will use the same reranking technique as my thesis\nTherefore, we will need to add another a reranking step using FinBERT-QA to recompute the scores of the answer matches returned by Jina.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<a href=\"https://raw.githubusercontent.com/yuanbit/financial-qa-search/master/img/query-flow.png\">\n<img src=\"/assets/images/blog/financial-qa/query-flow.png\" width=\"1000\">\n</a>\nQuery Flow\n</figure>\n<p></p>\n<p>Let us again walk through the steps one by one.</p>\n<h4 id=\"user-content-step-1-encode-question\">Step 1. Encode Question</h4>\n<p>Let's assume that the question text will be a user input. Jina will take this input and\ndefine a new Document.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/query-flow-step1.png\" width=\"500\">\nEncoder in the Query Flow\n</figure>\n<p></p>\n<p><strong>I. Add the Encoder to the Query Flow</strong></p>\n<p>Just like the encoding step of the Index Flow, we encode the questions using the same Encoder. Therefore, we can use the same Encoder from <code>pods/encode.yml</code>\nin our <strong>Query Flow</strong>. We will create a new <code>query.yml</code> file in the <code>flows</code> folder and\nadd the Encoder Pod to it:</p>\n\n<h4 id=\"user-content-step-2-search-indexes\">Step 2. Search Indexes</h4>\n<p>After encoding the questions, the question embeddings will be added to the Document by the Driver. This Document\nis then sent to the Indexer in the next Pod and the Driver will pass the question embeddings to the Indexer.\nThe Indexer will then search for the answers with the most similar embeddings using the k-nearest neighbors algorithm and\npass a list of top-k answer matches to the Driver to be added to the Document.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/query-flow-step2.png\" width=\"500\">\nThe Indexer will search for the answers with the most similar embeddings\n</figure>\n<p></p>\n<p>The matches will contain data\nsuch as the <code>docid</code>, <code>doc</code>, and match <code>scores</code>. Since we are also using the same\nIndexer from the Index Flow, all we need to do again is add the Indexer Pod to <code>flows/query.yml</code>:</p>\n\n<h4 id=\"user-content-step-3-reranking\">Step 3. Reranking</h4>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/blog/financial-qa/Ranker.png\" width=\"300\"></span>\n</p>\n<p>Let's assume that the Indexer returns the top-k answer matches at this point and we want to recompute the match scores to\nget better results. Jina has a class of Executors called the <strong>Rankers</strong>, in particular, the <strong>Match2DocRankers</strong>\nre-scores the matches for a query by calculating new scores. If you look at the Rankers on Jina Hub, the\n<a href=\"https://github.com/jina-ai/jina-hub/tree/master/rankers/LevenshteinRanker\">Levenshtein Ranker</a> uses the\nLevenshtein distance to recompute the match scores.</p>\n<p>However, instead of using a distance metric to recompute the scores, we want to load our fined-tuned BERT model,\nFinBERT-QA, in the Ranker and recompute the scores by using the concatenation of the question and the\ncurrent match answers as inputs into a binary classification task.</p>\n<p>In order to do this we need to <strong>create our own custom\nExecutor</strong> and implement our own logic. In this section we will use <strong>PyTorch</strong> and <strong>Hugging Face transformers</strong>\nto implement our custom Ranker.</p>\n<p>The main idea here is to pass our query text and the matches (containing the answer text and match scores) to the\nRanker to return a reordered list of matches based on the relevancy scores computed by FinBERT-QA. The Driver will\nthen update the matches in the Document based on this reordered list.</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/query-flow-step3.png\" width=\"550\">\nThe Ranker recomputes the scores of the matches using FinBERT-QA\n</figure>\n<p></p>\n<p>Recall that Peas can run in Docker, this means that we can simply <strong>build a Docker image with our implementation\nof the Ranker and use the image in the Query Flow.</strong> The Jina Hub API let's use to Cookiecutter to create the templates of all\nthe files we will need to do this. Let's get started by making sure that the Jina Hub extension is installed:</p>\n<pre><code class=\"hljs language-arduino\">pip install <span class=\"hljs-string\">\"jina[hub]\"</span>\n</code></pre>\n<h4 id=\"user-content-build-a-custom-executor\">Build a Custom Executor</h4>\n<p>Let's first create the templates that we will need to build a Docker image for our custom Ranker.</p>\n<p><strong>1.) Set up.</strong></p>\n<p>In the\n<code>financial-qa-search/</code>\ndirectory type:</p>\n<pre><code class=\"hljs language-arduino\">jina hub <span class=\"hljs-keyword\">new</span>\n</code></pre>\n<p>This will pop up a wizard that helps you walk through the process. Let's give our Executor the name <code>FinBertQARanker</code>\nand make sure to select <code>4 - Ranker</code> for the Executor type. We will use <code>jinaai/jina</code> as our base image for\nthe Docker image that we will build.</p>\n<pre><code class=\"hljs language-ini\">You've downloaded /Users/bithiah/.cookiecutters/cookiecutter-jina-hub before. Is it okay to delete and re-download it? <span class=\"hljs-section\">[yes]</span>: yes\nexecutor_name <span class=\"hljs-section\">[The class name of the executor (UpperCamelCase)]</span>: FinBertQARanker\nSelect executor_type:\n1 - Encoder\n2 - Crafter\n3 - Indexer\n4 - Ranker\n5 - Evaluator\nChoose from 1, 2, 3, 4, 5 <span class=\"hljs-section\">[1]</span>: 4\ndescription <span class=\"hljs-section\">[What does this executor do?]</span>: recomputes match scores using FinBERT-QA                \nkeywords <span class=\"hljs-section\">[keywords to describe the executor, separated by commas]</span>: \npip_requirements <span class=\"hljs-section\">[]</span>: \nbase_image <span class=\"hljs-section\">[jinaai/jina]</span>: \nauthor_name <span class=\"hljs-section\">[Jina AI Dev-Team (dev-team@jina.ai)]</span>: \nauthor_url <span class=\"hljs-section\">[https://jina.ai]</span>: \nauthor_vendor <span class=\"hljs-section\">[Jina AI Limited]</span>: \ndocs_url <span class=\"hljs-section\">[https://github.com/jina-ai/jina-hub]</span>: \nversion <span class=\"hljs-section\">[0.0.1]</span>: \nlicense <span class=\"hljs-section\">[apache-2.0]</span>: \n</code></pre>\n<p>After pressing Enter, you will see a new directory called <code>FinBertQARanker</code>. Your file structure should now look\nas follows:</p>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/file-structure.png\" width=\"650\">\nProject folder structure\n</figure>\n<p></p>\n<p>We will the implement our logic of the Ranker in <code>__init__.py</code>, write some tests in <code>tests/test_finbertqaranker.py</code>, and\nchange the <code>Dockerfile</code> to contain everything we need to build the image.</p>\n<p><strong>The code for the Ranker can be found <a href=\"https://github.com/jina-ai/examples/tree/example-financial-qa-search/financial-qa-search/FinBertQARanker\">here</a>.</strong></p>\n<p><strong>2.) Fill in the logic for reranking.</strong></p>\n<p>We will now implement our logic in <code>__init__.py</code>, which should look like the following:</p>\n\n<p>Jina contains different base classes for the Executors with different functionalities. The base Ranker class\nthat we will use is called <strong>Match2DocRankers</strong>, which has the functionality to recompute the match scores.</p>\n<p>Let's first change the base class of <code>BaseRanker</code> to <code>Match2DocRanker</code>.\nLet's also import <strong>PyTorch</strong> using Jina and some other modules that we will need as well as define our current directory.</p>\n\n<p>Our logic will be implemented in the <code>FinBertQARanker</code> class which will use <code>TorchDevice</code> and\n<code>Match2DocRanker</code> from Jina. We will download the models that we need in the <code>Dockerfile</code> later.\nLet us assume now we have two models in the folder <code>models/</code>: (1) <code>bert-qa/</code> and (2) <code>2_finbert-qa-50_512_16_3e6.pt</code>.</p>\n<p>(1) <code>bert-qa</code>: bert-base-uncased fine-tuned on the MS Macro dataset\nfrom <a href=\"https://github.com/nyu-dl/dl4marco-bert\">Passage Re-ranking with BERT</a></p>\n<p>(2) <code>2_finbert-qa-50_512_16_3e6.pt</code>: FinBERT-QA model - fine-tuned <code>bert-qa</code> on the FiQA dataset.</p>\n<p>We first specify <code>bert-qa/</code> as the the pre-trained model that would be used for initialization,\n<code>2_finbert-qa-50_512_16_3e6.pt</code> as the model that would be used to compute the QA relevancy scores,\nand the maximum sequence length for the QA pairs:</p>\n\n<p>Then we add a <code>post_init</code> function to the class to load the models for the binary classification task. Make sure to\nset the model in evaluation mode.</p>\n\n<p>Now let's implement a private <code>_get_score</code> function to compute each of the relevancy scores of the question\nand the top-k answer matches. We first concatenate the question and each top-k answer and encode them to get the\ninputs (<code>input_ids</code>, <code>token_type_ids</code>, <code>att_mask</code>) that the model needs using the\ntokenizer from transformers. We then feed the inputs into the model and get the prediction scores\nthat the QA pairs are relevant (<code>label = 1</code>). We apply the softmax function to the scores to transform the\nprediction scores into probabilities between 0 and 1. The output would then be the relevancy score in the form of a\nprobability for the QA pair.</p>\n\n<p>Lastly, let's fill in the scoring function that takes the question from the user and Jina's match scores as input\nand uses <code>_get_scores</code> to recompute new scores:</p>\n\n<p><strong>3.) Write a Unit Test</strong></p>\n<p>In order to create a new Executor and build a Docker image with the Jina Hub API, we need to write a unit test. We can\nfind a template for this in <code>tests/test_finbertqaranker.py</code>. I wrote a simple check to compute the relevance\nprobability for two answer matches given a query and to check to see if <code>FinBertQARanker</code> computes the same\nscore as our expectation:</p>\n\n<p><strong>4.) Add Requirements</strong></p>\n<p>Other than Jina we are also using PyTorch and transformers for <code>FinBertQARanker</code>, so let's add them\nto <code>FinBertQARanker/requirements.txt</code>:</p>\n<pre><code class=\"hljs language-ini\"><span class=\"hljs-attr\">torch</span>==<span class=\"hljs-number\">1.7</span>.<span class=\"hljs-number\">1</span>\n<span class=\"hljs-attr\">transformers</span>==<span class=\"hljs-number\">4.0</span>.<span class=\"hljs-number\">1</span>\n</code></pre>\n<p><strong>5.) Prepare Dockerfile</strong></p>\n<p>Let's change our <code>Dockerfile</code> to the contents below, which will download the models into a folder called <code>models/</code>.</p>\n\n<p><strong>6.) Build Docker image with Jina Hub API</strong></p>\n<p>We are finally ready to build <code>FinBertQARanker</code> into a Docker image. In our working directory, let's type:</p>\n<pre><code class=\"hljs language-css\">jina hub build FinBertQARanker/ <span class=\"hljs-attr\">--pull</span> <span class=\"hljs-attr\">--test-uses</span> <span class=\"hljs-attr\">--timeout-ready</span> <span class=\"hljs-number\">60000</span>\n</code></pre>\n<p><code>--pull</code> downloads our Jina base image if it is not already local.</p>\n<p><code>--test-uses</code> adds an extra test to check if the built image can dry-run successfully via Jina's Flow API.\n<code>--timeout-ready</code> gives our <code>post_init</code> function time to load the models.</p>\n<p>If the build is successful, you will see this message:</p>\n<pre><code class=\"hljs language-ruby\"> HubIO<span class=\"hljs-variable\">@10240</span>[I]<span class=\"hljs-symbol\">:Successfully</span> built ba3fac0f3a46\n HubIO<span class=\"hljs-variable\">@10240</span>[I]<span class=\"hljs-symbol\">:Successfully</span> tagged jinahub/pod.ranker.<span class=\"hljs-symbol\">finbertqaranker:</span><span class=\"hljs-number\">0.0</span>.<span class=\"hljs-number\">1</span>-<span class=\"hljs-number\">0.8</span>.<span class=\"hljs-number\">13</span>\n HubIO<span class=\"hljs-variable\">@10240</span>[I]<span class=\"hljs-symbol\">:building</span> FinBertQARanker/ takes <span class=\"hljs-number\">6</span> minutes <span class=\"hljs-keyword\">and</span> <span class=\"hljs-number\">12</span> seconds (<span class=\"hljs-number\">372</span>.31s)\n HubIO<span class=\"hljs-variable\">@10240</span>[S]<span class=\"hljs-symbol\">:</span>🎉 built jinahub/pod.ranker.<span class=\"hljs-symbol\">finbertqaranker:</span><span class=\"hljs-number\">0.0</span>.<span class=\"hljs-number\">1</span>-<span class=\"hljs-number\">0.8</span>.<span class=\"hljs-number\">13</span> (<span class=\"hljs-symbol\">sha256:</span>ba3fac0f3a) uncompressed <span class=\"hljs-symbol\">size:</span> <span class=\"hljs-number\">3.3</span> GB\n</code></pre>\n<p>Congratulations 🥳, you have successfully built a custom Executor in the form of a Docker image with the tag name\n<code>jinahub/pod.ranker.finbertqaranker:0.0.1-0.8.23</code>! Let's see how we can use it in the Query Flow next.</p>\n<p><strong>I. Create a custom Ranker Pod</strong></p>\n<p>To use our custom Ranker, <code>FinBertQARanker</code>, we need to first create a new Pod for the Ranker. Let's create\nthe file <code>rank.yml</code> in the <code>pods</code> folder. Next, let's copy the contents from <code>FinBertQARanker/config.yml</code>\nto <code>pods/rank.yml</code> and you should have the following:</p>\n\n<p>This is going to tell the Query Flow to use the logic we have implemented in our Exectuor, <code>FinBertQARanker/__init__.py</code>.\nSince the code for this implementation is loaded inside the <code>workspace</code> folder in the Docker image, let's add\n<code>workspace/</code> before <code>__init__.py</code>.</p>\n<p>The Encoder and Indexer Executors that we have used so far all use default Drivers in the Pods. Since we created our custom\nExecutor, we need to tell the Ranker Pod which Driver to use. In this case we will use the <code>Matches2DocRankDriver</code> for the\n<code>Match2DocRanker</code> base Ranker class. Hence, our <code>rank.yml</code> will look as follows:</p>\n\n<p>Hooray 🎊 we now have a custom Ranker Pod! Let's see next how we can use it in the Query Flow.</p>\n<p><strong>II. Use Custom Ranker in the Query Flow</strong></p>\n<p>Like the other Executor Pods, we just need to add <code>ranker</code> after the <code>doc_indexer</code> and tell the Query Flow to use\nthe Docker image and Ranker Pod that we have just created by specifying the prefix <code>docker://</code> in front of the tag name. The final <code>flows/query.yml</code> should look as follows:</p>\n\n<p><strong>Be aware that the tag name of the Docker image might change</strong> depending the current Jina release. Make sure to change the\ntag name that accordingly to your build message.</p>\n<p>We can again visualize the Query Flow using the Flow API in a  <code>jupyter notebook</code> as follows:</p>\n\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/query-flow-jina.png\" width=\"1000\">\nQuery Flow visualization\n</figure>\n<p></p>\n<p>Here we see our Query Flow with three Pods containing the Encoder, <code>encoder</code> and Indexer, <code>doc_indexer</code>,\nand Ranker, <code>ranker</code>.\nAt the end of the Query Flow, the Driver from the Ranker Pod will have changed the matches in the Document to an reordered list of\nmatches based on the probabilities computed by our custom Ranker, <code>FinBertQARanker</code>. Next, we will see how we can\naccess this list of final matches in our <code>app.py</code>.</p>\n<h4 id=\"user-content-build-a-search-application\">Build a Search Application</h4>\n<p align=\"center\" class=\"image-only\">\n</p><figure>\n<img src=\"/assets/images/blog/financial-qa/query-flow-step4.png\" width=\"550\">\nGet matches and scores stored in the Document\n</figure>\n<p></p>\n<p>Since our final matches and their relevancy probability are stored in the Document, in <code>app.py</code>, we can\nwrite a function to print out the response to a question from the user input. We can loop through the matches in our\nDocument, <code>d.matches</code>, and print out the values of the scores and the matching answer text.</p>\n\n<p>We can then write our <code>search</code> method that uses the Query Flow from <code>flows/query.yml</code> and passes\nthe user inputs into <code>print_resp</code>. In <code>f.search_lines()</code>, we specify the input as our user query,\nthe output as the response to be printed, and the top-k answers we want to retrieve. The cool thing about\n<code>f.search_lines()</code> is that it automatically creates a Document for the user query, like sugar magic 🍬!</p>\n\n<p>Hooray! 🎉🎉🎉 We have just finished building our Financial QA search engine! We can now run:</p>\n<p><code>python app.py search</code></p>\n<p>and try out different questions! The Ranker might take some time to compute the relevancy\nscores since it is using a BERT-based model. Here is a list of sample questions:</p>\n<pre><code class=\"hljs language-sql\">• What does it mean that stocks <span class=\"hljs-keyword\">are</span> “memoryless”?\n• What would a stock be worth if dividends did <span class=\"hljs-keyword\">not</span> exist?\n• What <span class=\"hljs-keyword\">are</span> the risks <span class=\"hljs-keyword\">of</span> Dividend<span class=\"hljs-operator\">-</span>yielding stocks?\n• Why do financial institutions charge so much <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">convert</span> currency?\n• <span class=\"hljs-keyword\">Is</span> there a candlestick <span class=\"hljs-keyword\">pattern</span> that guarantees <span class=\"hljs-keyword\">any</span> kind <span class=\"hljs-keyword\">of</span> future profit?\n• <span class=\"hljs-number\">15</span> <span class=\"hljs-keyword\">year</span> mortgage vs <span class=\"hljs-number\">30</span> <span class=\"hljs-keyword\">year</span> paid off <span class=\"hljs-keyword\">in</span> <span class=\"hljs-number\">15</span>\n• Why <span class=\"hljs-keyword\">is</span> it rational <span class=\"hljs-keyword\">to</span> pay <span class=\"hljs-keyword\">out</span> a dividend?\n• Why do companies have a fiscal <span class=\"hljs-keyword\">year</span> different <span class=\"hljs-keyword\">from</span> the calendar <span class=\"hljs-keyword\">year</span>?\n• What should I look <span class=\"hljs-keyword\">at</span> before investing <span class=\"hljs-keyword\">in</span> a <span class=\"hljs-keyword\">start</span><span class=\"hljs-operator\">-</span>up?\n• <span class=\"hljs-keyword\">Where</span> do <span class=\"hljs-keyword\">large</span> corporations store their massive amounts <span class=\"hljs-keyword\">of</span> cash?\n</code></pre>\n<p align=\"center\" class=\"image-only\">\n<span class=\"image-wrapper\"><img src=\"/assets/images/blog/financial-qa/search-results.png\" width=\"900\"></span>\n</p>\n<h2 id=\"user-content-summary\">Summary</h2>\n<p>In this blog, I introduced core Jina concepts and demonstrated how to build a production-ready Financial QA system using Jina.\nI also explained how to use the Jina Hub API to create a BERT-powered Ranker Executor. Thanks to\nthe building blocks that Jina provides, we could easily use the SOTA and powerful model, FinBERT-QA, in production.</p>\n<p>The neural search application we have just built with Jina runs locally on our own machines, but can also\nbe completely distributed and run on multiple machines in a network, making our application highly reusable, scalable,\nand efficient. On top of that, common cloud-native features such as persistence, scheduling, chaining, grouping, and\nparallelization all come out of the box.</p>\n<p>Moreover, there are variants of pre-trained BERT models for other domains such as <a href=\"https://github.com/dmis-lab/biobert\">biomedical</a>,\n<a href=\"https://github.com/allenai/scibert\">science</a>, and <a href=\"https://huggingface.co/nlpaueb/legal-bert-base-uncased\">legal</a>.\nYou can use these models to build a QA search application and experiment with the results!</p>\n<h2 id=\"user-content-next-step-evaluation\">Next Step: Evaluation</h2>\n<p>If you made it all the way through this tutorial, you might be wondering, <strong>\"how do I evaluate the search results?\"</strong>.\nGreat question! Jina has a class of Executors called the <strong>Evaluator</strong> and has implementations of common evaluation\nmetrics like Precision and Reciprocal Error. Evaluation is an important step and will allow us to optimize\nthe search results and design the most effective Flows. We will see in the next tutorial how we can add the\nEvaluator in our Financial QA application.</p>\n<h2 id=\"user-content-learn-more\">Learn More</h2>\n<p>To learn more about Jina, I recommend reading the following articles:</p>\n<ul>\n<li><a href=\"https://medium.com/jina-ai/what-is-jina-and-neural-search-7a9e166608ab\">What is Jina and Neural Search?</a></li>\n<li><a href=\"https://hanxiao.io/2020/10/19/A-Curated-List-of-Neural-Search-and-Jina-Framework-Designs/\">From Then to Now: a Curated List for Neural Search and Jina</a></li>\n</ul>\n<p>and checking out our <a href=\"https://github.com/jina-ai/jina\">Github</a> page!</p>\n<p>If you want to learn Jina by doing, I encourage you to start building your own examples and\nsharing them with the community to help us grow our open-source ecosystem! 🚀 For example, check out this\n<a href=\"https://github.com/ArturTan/transformers-for-lawyers\">community project - transformers-for-lawyers</a> built with Jina.</p>\n<p>We saw how versatile and extensible Jina is and we could create all kinds of search applications using our own\nlogic and models for NLP, Computer Vision, and other ML search applications.\n<strong><a href=\"https://github.com/jina-ai/jina-hub\">Jina Hub</a> is a great place to get started, where you can use\nthe available Executors to build other types of search engines (for images, videos, etc...) or create your own\nExecutors using the Jina Hub API!</strong> You can always come back to this tutorial and walk through the process again.</p>\n<p><strong>As an open-source company we would also love your help and contributions.️</strong> We have issues labelled as <a href=\"https://github.com/jina-ai/jina/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22\">good first issue</a>\nto get started! You can read more about our contributing guidelines <a href=\"https://github.com/jina-ai/jina/blob/master/CONTRIBUTING.md\">here</a>.</p>\n<p>If you want to know more about Jina's new features or ask any questions, welcome to join our <a href=\"https://slack.jina.ai/\">Slack Community</a>\nand our monthly public <a href=\"https://hanxiao.io/2020/08/06/Engineering-All-Hands-in-Public/\">Engineering All Hands</a> via\nZoom or Youtube live stream.</p>\n<p>If you are interested in joining us as a full-time AI / Backend / Frontend developer,\nplease submit your CV to our <a href=\"jobs.jina.ai\">job portal</a>. Let’s build the next open-source neural search ecosystem together!</p>\n<h2 id=\"user-content-community\">Community</h2>\n<ul>\n<li><a href=\"slack.jina.ai\">Slack channel</a> - a communication platform for developers to discuss Jina</li>\n<li><a href=\"mailto:newsletter+subscribe@jina.ai\">Community newsletter</a> - subscribe to the latest update, release and event news of Jina</li>\n<li><a href=\"https://www.linkedin.com/company/jinaai/\">LinkedIn</a> - get to know Jina AI as a company and find job opportunities</li>\n<li><a href=\"https://twitter.com/JinaAI_\">Twitter</a> - follow us and interact with us using hashtag <code>#JinaSearch</code></li>\n<li><a href=\"https://jina.ai\">Company</a> - know more about our company, we are fully committed to open-source!</li>\n</ul>","coverImage":"/assets/images/blog/financial-qa.png","tags":["Financial Q&A","BERT"]}},"__N_SSG":true}